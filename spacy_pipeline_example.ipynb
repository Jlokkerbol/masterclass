{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy_pipeline_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jlokkerbol/masterclass/blob/main/spacy_pipeline_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEhki4Kvk438",
        "outputId": "ce07cad9-631c-4072-c1d6-83fe3ef95c42"
      },
      "source": [
        "!pip install -U pendulum spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pendulum\n",
            "  Downloading pendulum-2.1.2-cp37-cp37m-manylinux1_x86_64.whl (155 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 155 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.6 in /usr/local/lib/python3.7/dist-packages (from pendulum) (2.8.2)\n",
            "Collecting pytzdata>=2020.1\n",
            "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
            "\u001b[K     |████████████████████████████████| 489 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0,>=2.6->pendulum) (1.15.0)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 606 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pytzdata, pathy, langcodes, spacy, pendulum\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pendulum-2.1.2 pydantic-1.8.2 pytzdata-2020.1 spacy-3.2.0 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAZYivIDqoDW",
        "outputId": "4515509a-0f26-4f2d-f1d3-a07a6e94b793"
      },
      "source": [
        "!python -m spacy download nl_core_news_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nl-core-news-lg==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/nl_core_news_lg-3.2.0/nl_core_news_lg-3.2.0-py3-none-any.whl (572.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 572.6 MB 7.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from nl-core-news-lg==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->nl-core-news-lg==3.2.0) (2.0.1)\n",
            "Installing collected packages: nl-core-news-lg\n",
            "Successfully installed nl-core-news-lg-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('nl_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gH9ueGhkreG"
      },
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier, BalancedBaggingClassifier    \n",
        "import pandas as pd\n",
        "import pendulum\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import spacy\n",
        "\n",
        "\n",
        "# only use 2019 data as example\n",
        "df = pd.read_parquet(\"https://github.com/jads-nl/public-lectures/blob/main/nlp/data/dutch-restaurant-reviews-per-year/reviewYear%3D2019/058d741d776d45f18e0ccc51f71173dc.parquet?raw=true\")\n",
        "\n",
        "# initatie spacy model\n",
        "nlp = spacy.load(\"nl_core_news_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qgTwtqclyiS"
      },
      "source": [
        "# Dutch Restaurant reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdLt0vnlp_3c"
      },
      "source": [
        "## Objective\n",
        "Predict a 'detractor' such that restaurant owner can look-up interesting (negative) feedback and act upon that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um0Kzo9HqB-u"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pFiAZpeni-R"
      },
      "source": [
        "### Select main columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq5--vRCnWpV"
      },
      "source": [
        "reviews = df.loc[:, ['restoId', 'reviewerId', 'reviewerFame', 'reviewerNumReviews', 'reviewText']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOV7SzHNnYtH"
      },
      "source": [
        "### Format date columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cli4hW9k1Yz"
      },
      "source": [
        "def parse_date(date):\n",
        "    return pendulum.from_format(date, fmt=\"D MMM YYYY\", locale=\"nl\")\n",
        "\n",
        "reviews[\"reviewDate\"] = df.reviewDate.apply(parse_date).dt.date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93z9CaHLmhOo"
      },
      "source": [
        "### Format numerical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoQkhlkGnyOz"
      },
      "source": [
        "def clean_price(string):\n",
        "    \"Remove euro sign and whitespace in price\"\n",
        "    if string:\n",
        "        return float(string.split(\" \")[-1])\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "reviews[\"avgPrice\"] = df[\"avgPrice\"].fillna(0).apply(clean_price)\n",
        "\n",
        "\n",
        "# numerical columns have comma as decimal seperator --> cast to floats\n",
        "numerical_cols = [\n",
        "    \"scoreFood\",\n",
        "    \"scoreService\",\n",
        "    \"scoreDecor\",\n",
        "    \"reviewScoreOverall\",\n",
        "    \"scoreTotal\",\n",
        "]\n",
        "for col in numerical_cols:\n",
        "    reviews[col] = pd.to_numeric(df[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-u5eSdSoBjT"
      },
      "source": [
        "### Format ordinal columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZjO0HKVoRUX"
      },
      "source": [
        "map_scores = {\n",
        "    \"waitingTimeScore\": {\n",
        "        None: 0,\n",
        "        \"Hoog tempo\": 1,\n",
        "        \"Kort\": 2,\n",
        "        \"Redelijk\": 3,\n",
        "        \"Kan beter\": 4,\n",
        "        \"Lang\": 5,\n",
        "    },\n",
        "    \"valueForPriceScore\": {\n",
        "        None: 0,\n",
        "        \"Erg gunstig\": 1,\n",
        "        \"Gunstig\": 2,\n",
        "        \"Redelijk\": 3,\n",
        "        \"Precies goed\": 4,\n",
        "        \"Kan beter\": 5,\n",
        "    },\n",
        "    \"noiseLevelScore\": {\n",
        "        None: 0,\n",
        "        \"Erg rustig\": 1,\n",
        "        \"Rustig\": 2,\n",
        "        \"Precies goed\": 3,\n",
        "        \"Rumoerig\": 4,\n",
        "    },\n",
        "    \"reviewerFame\": {\n",
        "        None: 0,\n",
        "        \"Proever\": 1,\n",
        "        \"Fijnproever\": 2,\n",
        "        \"Expertproever\": 3,\n",
        "        \"Meesterproever\": 4\n",
        "    }\n",
        "}\n",
        "\n",
        "for col in map_scores.keys():\n",
        "    reviews[col] = (\n",
        "        df[col].apply(lambda x: map_scores[col].get(x, None)).astype(\"Int64\")\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VCQPqZKp4AK"
      },
      "source": [
        "## Text pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vPzKjnurVVb"
      },
      "source": [
        "### Filter reviews that are short or in process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxs-NOL5r5o3"
      },
      "source": [
        "def validate_review(review):\n",
        "    if review == '- Recensie is momenteel in behandeling -' or len(review) < 4:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "    \n",
        "\n",
        "reviews['is_valid'] = reviews.reviewText.apply(validate_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BXVyWnQvZ9P"
      },
      "source": [
        "### Add simple features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uma80i9vmd_"
      },
      "source": [
        "reviews['review_char_length_'] = df.reviewText.apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkgXBreJsH8z"
      },
      "source": [
        "### Tokenize and create Document-Term Matrix\n",
        "\n",
        "We will use [pandas sparse data structures](https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html) to save memory. Note cell below takes about 9 minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-HflkHnscpd",
        "outputId": "5a178123-2b1a-4392-b3ec-61f26ef01828"
      },
      "source": [
        "%%time\n",
        "def tokenize_simple(text):\n",
        "    \"\"\"Tokenizer returning lowercase tokens with no stop words, no punctuation and no words with encoding errors\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.lower_ for token in doc if not (token.is_stop or token.is_punct or (\"\\\\\" in token.lower_))]\n",
        "\n",
        "\n",
        "# some abbreviations aren't in spaCy's default Dutch stopwords list, so we add them\n",
        "stop_words = nlp.Defaults.stop_words.update(['n', 't'])\n",
        "\n",
        "count_vectorizer = CountVectorizer(tokenizer=tokenize_simple, stop_words=stop_words, ngram_range=(1,1))\n",
        "dtm = pd.DataFrame.sparse.from_spmatrix(count_vectorizer.fit_transform(reviews.reviewText), columns=count_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 14s, sys: 2.04 s, total: 9min 16s\n",
            "Wall time: 9min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMK0eFY9NZrz"
      },
      "source": [
        "We will only keep words in the DTM that occur twice or more over all the reviews. This reduces the width of the DTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOzA_2btLesV",
        "outputId": "61ece71f-d793-44dd-d32b-b0a523c3af13"
      },
      "source": [
        "token_filter = (dtm.sum() > 2)\n",
        "token_filter[token_filter == True]\n",
        "print(f\"Full DTM: {dtm.shape}\")\n",
        "print(f\"Filtered DTM: {dtm.loc[:, token_filter].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full DTM: (47048, 32823)\n",
            "Filtered DTM: (47048, 11050)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QOmgqE2w6Yw"
      },
      "source": [
        "## Binary classification: `is_detractor`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMfvALr-xxkc"
      },
      "source": [
        "### Define Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlsdS0FZx2Kc"
      },
      "source": [
        "reviews[\"is_detractor\"] = reviews.reviewScoreOverall.apply(lambda x: True if x <= 6 else False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVQwGzDeyER4"
      },
      "source": [
        "### Train-test split\n",
        "\n",
        "(Cell below takes about two minute)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fRiXteyFiF",
        "outputId": "9aa72c62-cd7a-46c5-eaf1-89945883e53a"
      },
      "source": [
        "%%time\n",
        "X = reviews[reviews.is_valid].drop(columns=[\"reviewDate\", \"reviewText\", \"scoreFood\", \"scoreService\", \"scoreDecor\", \"reviewScoreOverall\", \"scoreTotal\", \"is_detractor\"])\n",
        "y = reviews[reviews.is_valid].is_detractor\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(X,y):\n",
        "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    dtm_train, dtm_test = dtm.loc[reviews.is_valid, token_filter].iloc[train_index, :], dtm.loc[reviews.is_valid, token_filter].iloc[test_index, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 41s, sys: 2.68 s, total: 1min 44s\n",
            "Wall time: 1min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lmhRBHs8pe7"
      },
      "source": [
        "### BaggingClassifier - without DTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqIYp3-c_9Tq"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fost6IdJK8pS",
        "outputId": "c6d9b9b7-2cfc-4828-93f4-dc10ca4dd330"
      },
      "source": [
        "#%%time\n",
        "clf1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
        "                                bootstrap=False,\n",
        "                                random_state=0)\n",
        "clf1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
              "                  random_state=0)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z62HRMZxK8pU"
      },
      "source": [
        "We will skip fine-tuning the model, our purpose is to compare it with a model that adds text. Using the balanced accuracy to compare, which is defined as the average of recall obtained on each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx7_U1swK8pU",
        "outputId": "88304838-0dc1-4963-aca0-c3406d36032c"
      },
      "source": [
        "balanced_accuracy_score(y_test, clf1.predict(X_test)).round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.66"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHrR5vFCK8pV"
      },
      "source": [
        "### BaggingClassifier - with DTM\n",
        "\n",
        "(Cell below takes about 5 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsiZpGtYDybb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXDJU5PgK8pV",
        "outputId": "f8205ac2-7392-4052-f23b-fce969a9b15b"
      },
      "source": [
        "%%time\n",
        "clf2 = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
        "                                bootstrap=False,\n",
        "                                random_state=0)\n",
        "clf2.fit(dtm_train.join(X_train), y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:617: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  \"pandas.DataFrame with sparse columns found.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 25min 31s, sys: 11.3 s, total: 25min 42s\n",
            "Wall time: 25min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2qh0773Jfqp",
        "outputId": "d6b468c4-6084-4afe-c85c-dbdd644b7324"
      },
      "source": [
        "balanced_accuracy_score(y_test, clf2.predict(dtm_test.join(X_test))).round(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:617: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  \"pandas.DataFrame with sparse columns found.\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.704"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3oblv62bZqo"
      },
      "source": [
        "## Closing remarks\n",
        "\n",
        "We have illustrated how a simple bag-of-words model can add to the performance of a classifier that uses structured data. We haven't optimized the modeling at all, but done a simple like-to-like comparison with the same parameters.\n",
        "\n",
        "Note that working with text requires more engineering: you need to make decisions about how to store and process the data because it can quickly expand beyond the memory of your (virtual) machine. Even with this simple model, we have used over 700 features from a truncated document-term matrix."
      ]
    }
  ]
}