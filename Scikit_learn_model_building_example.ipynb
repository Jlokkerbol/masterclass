{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-learn_model_building_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsnBQbvV//wFf8fltovbpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jlokkerbol/masterclass/blob/main/Scikit_learn_model_building_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iru8mbpme2Ch"
      },
      "source": [
        "# Sklearn model building example\n",
        "\n",
        "Sklearn has an extensive user guide, to be found at: https://scikit-learn.org/stable/\n",
        "\n",
        "Below we go through an example pipeline, where some fundamental applications of sklearn are demonstrated for building a machine learning model.\n",
        "\n",
        "Needless to say, there is much, much more to sklearn than shown below. Please do visit https://scikit-learn.org/stable/ to get a glimpse of all the possibilities of this important package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qB--SMu81rW"
      },
      "source": [
        "#import relevant modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQVPxDXjEzo"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "EtEXZweE9NPD",
        "outputId": "ee40c651-116e-47ff-f40e-09dcfd99a8d6"
      },
      "source": [
        "#load the Sonar data, containing 60 attributes, with the aim to classify \n",
        "# objects as Mine or Rock\n",
        "# more information to be found at: https://datahub.io/machine-learning/sonar\n",
        "df = pd.read_csv('https://datahub.io/machine-learning/sonar/r/sonar.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0ee5ea6-2c2d-46d7-8390-64e329e99e93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ee5ea6-2c2d-46d7-8390-64e329e99e93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0ee5ea6-2c2d-46d7-8390-64e329e99e93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0ee5ea6-2c2d-46d7-8390-64e329e99e93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  ...  attribute_59  attribute_60  Class\n",
              "0       0.0200       0.0371       0.0428  ...        0.0090        0.0032   Rock\n",
              "1       0.0453       0.0523       0.0843  ...        0.0052        0.0044   Rock\n",
              "2       0.0262       0.0582       0.1099  ...        0.0095        0.0078   Rock\n",
              "3       0.0100       0.0171       0.0623  ...        0.0040        0.0117   Rock\n",
              "4       0.0762       0.0666       0.0481  ...        0.0107        0.0094   Rock\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-NnpFZ7Eu9p",
        "outputId": "ed1dfa92-5b7f-44a4-b089-20c5a619bae2"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   attribute_1   208 non-null    float64\n",
            " 1   attribute_2   208 non-null    float64\n",
            " 2   attribute_3   208 non-null    float64\n",
            " 3   attribute_4   208 non-null    float64\n",
            " 4   attribute_5   208 non-null    float64\n",
            " 5   attribute_6   208 non-null    float64\n",
            " 6   attribute_7   208 non-null    float64\n",
            " 7   attribute_8   208 non-null    float64\n",
            " 8   attribute_9   208 non-null    float64\n",
            " 9   attribute_10  208 non-null    float64\n",
            " 10  attribute_11  208 non-null    float64\n",
            " 11  attribute_12  208 non-null    float64\n",
            " 12  attribute_13  208 non-null    float64\n",
            " 13  attribute_14  208 non-null    float64\n",
            " 14  attribute_15  208 non-null    float64\n",
            " 15  attribute_16  208 non-null    float64\n",
            " 16  attribute_17  208 non-null    float64\n",
            " 17  attribute_18  208 non-null    float64\n",
            " 18  attribute_19  208 non-null    float64\n",
            " 19  attribute_20  208 non-null    float64\n",
            " 20  attribute_21  208 non-null    float64\n",
            " 21  attribute_22  208 non-null    float64\n",
            " 22  attribute_23  208 non-null    float64\n",
            " 23  attribute_24  208 non-null    float64\n",
            " 24  attribute_25  208 non-null    float64\n",
            " 25  attribute_26  208 non-null    float64\n",
            " 26  attribute_27  208 non-null    float64\n",
            " 27  attribute_28  208 non-null    float64\n",
            " 28  attribute_29  208 non-null    float64\n",
            " 29  attribute_30  208 non-null    float64\n",
            " 30  attribute_31  208 non-null    float64\n",
            " 31  attribute_32  208 non-null    float64\n",
            " 32  attribute_33  208 non-null    float64\n",
            " 33  attribute_34  208 non-null    float64\n",
            " 34  attribute_35  208 non-null    float64\n",
            " 35  attribute_36  208 non-null    float64\n",
            " 36  attribute_37  208 non-null    float64\n",
            " 37  attribute_38  208 non-null    float64\n",
            " 38  attribute_39  208 non-null    float64\n",
            " 39  attribute_40  208 non-null    float64\n",
            " 40  attribute_41  208 non-null    float64\n",
            " 41  attribute_42  208 non-null    float64\n",
            " 42  attribute_43  208 non-null    float64\n",
            " 43  attribute_44  208 non-null    float64\n",
            " 44  attribute_45  208 non-null    float64\n",
            " 45  attribute_46  208 non-null    float64\n",
            " 46  attribute_47  208 non-null    float64\n",
            " 47  attribute_48  208 non-null    float64\n",
            " 48  attribute_49  208 non-null    float64\n",
            " 49  attribute_50  208 non-null    float64\n",
            " 50  attribute_51  208 non-null    float64\n",
            " 51  attribute_52  208 non-null    float64\n",
            " 52  attribute_53  208 non-null    float64\n",
            " 53  attribute_54  208 non-null    float64\n",
            " 54  attribute_55  208 non-null    float64\n",
            " 55  attribute_56  208 non-null    float64\n",
            " 56  attribute_57  208 non-null    float64\n",
            " 57  attribute_58  208 non-null    float64\n",
            " 58  attribute_59  208 non-null    float64\n",
            " 59  attribute_60  208 non-null    float64\n",
            " 60  Class         208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGa7Cpl0Dj1N"
      },
      "source": [
        "As we have no categorical features in our data (only the outcome variable Class is categorical, we add two categorical features to our data, such that we can demonstrate the functionalities relating to this data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "_5ddr3E6EoSd",
        "outputId": "c09a370c-a04a-44ee-a870-84108cf8d297"
      },
      "source": [
        "# add two fictive categorical features\n",
        "df['batch'] = ['first']*60+['second']*60 + ['third']* (len(df)-60-60)\n",
        "df['location'] = ['loc_A']*20+['loc_B']*30 +['loc_C']*40 +['loc_D']*50 + ['loc_E']* (len(df)-20-30-40-50)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f05cbbf-8678-4612-a1cb-7565aadce0a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "      <th>batch</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f05cbbf-8678-4612-a1cb-7565aadce0a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f05cbbf-8678-4612-a1cb-7565aadce0a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f05cbbf-8678-4612-a1cb-7565aadce0a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  ...  Class  batch  location\n",
              "0       0.0200       0.0371       0.0428  ...   Rock  first     loc_A\n",
              "1       0.0453       0.0523       0.0843  ...   Rock  first     loc_A\n",
              "2       0.0262       0.0582       0.1099  ...   Rock  first     loc_A\n",
              "3       0.0100       0.0171       0.0623  ...   Rock  first     loc_A\n",
              "4       0.0762       0.0666       0.0481  ...   Rock  first     loc_A\n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekZuHB10GLRL",
        "outputId": "5a7c478e-796a-488d-9295-235113b89411"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 63 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   attribute_1   208 non-null    float64\n",
            " 1   attribute_2   208 non-null    float64\n",
            " 2   attribute_3   208 non-null    float64\n",
            " 3   attribute_4   208 non-null    float64\n",
            " 4   attribute_5   208 non-null    float64\n",
            " 5   attribute_6   208 non-null    float64\n",
            " 6   attribute_7   208 non-null    float64\n",
            " 7   attribute_8   208 non-null    float64\n",
            " 8   attribute_9   208 non-null    float64\n",
            " 9   attribute_10  208 non-null    float64\n",
            " 10  attribute_11  208 non-null    float64\n",
            " 11  attribute_12  208 non-null    float64\n",
            " 12  attribute_13  208 non-null    float64\n",
            " 13  attribute_14  208 non-null    float64\n",
            " 14  attribute_15  208 non-null    float64\n",
            " 15  attribute_16  208 non-null    float64\n",
            " 16  attribute_17  208 non-null    float64\n",
            " 17  attribute_18  208 non-null    float64\n",
            " 18  attribute_19  208 non-null    float64\n",
            " 19  attribute_20  208 non-null    float64\n",
            " 20  attribute_21  208 non-null    float64\n",
            " 21  attribute_22  208 non-null    float64\n",
            " 22  attribute_23  208 non-null    float64\n",
            " 23  attribute_24  208 non-null    float64\n",
            " 24  attribute_25  208 non-null    float64\n",
            " 25  attribute_26  208 non-null    float64\n",
            " 26  attribute_27  208 non-null    float64\n",
            " 27  attribute_28  208 non-null    float64\n",
            " 28  attribute_29  208 non-null    float64\n",
            " 29  attribute_30  208 non-null    float64\n",
            " 30  attribute_31  208 non-null    float64\n",
            " 31  attribute_32  208 non-null    float64\n",
            " 32  attribute_33  208 non-null    float64\n",
            " 33  attribute_34  208 non-null    float64\n",
            " 34  attribute_35  208 non-null    float64\n",
            " 35  attribute_36  208 non-null    float64\n",
            " 36  attribute_37  208 non-null    float64\n",
            " 37  attribute_38  208 non-null    float64\n",
            " 38  attribute_39  208 non-null    float64\n",
            " 39  attribute_40  208 non-null    float64\n",
            " 40  attribute_41  208 non-null    float64\n",
            " 41  attribute_42  208 non-null    float64\n",
            " 42  attribute_43  208 non-null    float64\n",
            " 43  attribute_44  208 non-null    float64\n",
            " 44  attribute_45  208 non-null    float64\n",
            " 45  attribute_46  208 non-null    float64\n",
            " 46  attribute_47  208 non-null    float64\n",
            " 47  attribute_48  208 non-null    float64\n",
            " 48  attribute_49  208 non-null    float64\n",
            " 49  attribute_50  208 non-null    float64\n",
            " 50  attribute_51  208 non-null    float64\n",
            " 51  attribute_52  208 non-null    float64\n",
            " 52  attribute_53  208 non-null    float64\n",
            " 53  attribute_54  208 non-null    float64\n",
            " 54  attribute_55  208 non-null    float64\n",
            " 55  attribute_56  208 non-null    float64\n",
            " 56  attribute_57  208 non-null    float64\n",
            " 57  attribute_58  208 non-null    float64\n",
            " 58  attribute_59  208 non-null    float64\n",
            " 59  attribute_60  208 non-null    float64\n",
            " 60  Class         208 non-null    object \n",
            " 61  batch         208 non-null    object \n",
            " 62  location      208 non-null    object \n",
            "dtypes: float64(60), object(3)\n",
            "memory usage: 102.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNq-OW3fhdhR"
      },
      "source": [
        "As this dataset does not have any missings, we will introduce some random missings such that we are forced to make use of more sklearn preprocessing functionalities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLXEDvVshcxq",
        "outputId": "52e5f0bd-20da-4bc0-e088-f57c56505c78"
      },
      "source": [
        "np.random.seed(42)\n",
        "mask = np.random.choice([True, False], p=[0.1, 0.9], size=df.shape)\n",
        "mask"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False,  True,  True],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "vnZ-wmdXiyRE",
        "outputId": "7e9cac6f-7659-4399-ae56-6fba28bcaf3a"
      },
      "source": [
        "# replace original df:\n",
        "df = df.mask(mask)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e910b11a-0d2b-47b8-b78c-d6163d6cd40a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>Class</th>\n",
              "      <th>batch</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>Rock</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>first</td>\n",
              "      <td>loc_A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e910b11a-0d2b-47b8-b78c-d6163d6cd40a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e910b11a-0d2b-47b8-b78c-d6163d6cd40a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e910b11a-0d2b-47b8-b78c-d6163d6cd40a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  attribute_3  ...  Class  batch  location\n",
              "0       0.0200       0.0371       0.0428  ...   Rock  first     loc_A\n",
              "1       0.0453       0.0523       0.0843  ...   Rock  first     loc_A\n",
              "2       0.0262       0.0582          NaN  ...   Rock  first     loc_A\n",
              "3       0.0100          NaN       0.0623  ...   Rock  first     loc_A\n",
              "4       0.0762       0.0666       0.0481  ...    NaN  first     loc_A\n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp4yf_SIjN8L"
      },
      "source": [
        "The next step is to split the data into a random train (70%) and test (30%) set, such that we can perform model selection in the next section on the train set, and finally perform model assessment on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDRA7xvD_HUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "3695dc85-e95f-490d-dd36-b4883d2107f7"
      },
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in split.split(df, df['Class']):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2d45184db8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mstrat_train_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mstrat_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \"\"\"\n\u001b[0;32m-> 2022\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2023\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input contains NaN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRVlbzbnceO"
      },
      "source": [
        "This is not working due to missings in the outcome variable, which causes StratifiedShuffleSplit to fail, because we ask it to perform a split where the distribution of our outcome variable Class is comparable across both the train and test set. And when the outcome variable Class contains missings, that procedure fails.\n",
        "\n",
        "This puts us in a Catch 22, as we cannot impute the outcome variable using only the training data on outcomes, as our training data has to be defined based on our outcome variable. Please note this will not be a problem when the split between train and test data is not done randomly, but based on time, or location. In our case, however, it is a problem, and this is typically the point where you check whether the missing outcome data can be retrieved through other means, where you decide to drop missings, or decide to impute the outcome data. \n",
        "\n",
        "We will impute the missing outcome values with the most occurring value, and use the preprocessing functionality of sklearn for this task. We will use this functionality again after splitting the data to impute missings in the predictors, as this will ensure that we do the exact same preprocessing on the predictors in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTpgvSAHpgGE",
        "outputId": "03b373b3-c6a2-467c-dc99-c41fb732b700"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_outcome = SimpleImputer(strategy = 'most_frequent')\n",
        "imp_outcome.fit(df['Class'].to_frame())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(strategy='most_frequent')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrG_BLhQvv9I"
      },
      "source": [
        "The code above created an 'impute object' that has been fitted on df['Class'] to determine what the imputation value should be. The imputation value is shown below (and equals 'Mine', which is indeed the most_frequent value in df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLqHSvLuqc9",
        "outputId": "a93d7201-7230-4557-eb03-af918b0f77d7"
      },
      "source": [
        "imp_outcome.statistics_"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mine'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMp1CLAxwF9B"
      },
      "source": [
        "df['Class'] now still contains missings, which will be imputed after we use 'transform' on df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7hTPYk9wTAb",
        "outputId": "084e3ee2-52e0-45bd-fca5-d53a51873f49"
      },
      "source": [
        "sum(df['Class'].isnull())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yhQtbMMwd0n",
        "outputId": "3edadcac-a857-4497-de23-f878a3b039a4"
      },
      "source": [
        "df['Class'] = imp_outcome.transform(df['Class'].to_frame())\n",
        "sum(df['Class'].isnull())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxwb1lpws8h"
      },
      "source": [
        "We could have done both the fitting and transforming in one go using the command imp_outcome.fit_transform().\n",
        "\n",
        "We are now ready to proceed with splitting the data into a train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LlSGNPzw0t0"
      },
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "for train_index, test_index in split.split(df, df['Class']):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5t8ibImAlV3",
        "outputId": "fb58ab90-a4ee-4cea-be9d-51b8b8ff52f8"
      },
      "source": [
        "#check if this resulted in a 70% train set and 30% test set with equal outcome distributions\n",
        "print('share of observations in the train set:', str(round(len(strat_train_set)/len(df), 3)))\n",
        "print('share of observations in the test set:', str(round(len(strat_test_set)/len(df), 3)))\n",
        "print('share of mines in the train set:', str(round(len(strat_train_set.loc[strat_train_set['Class'] == 'Mine'])/len(strat_train_set), 3)))\n",
        "print('share of mines in the test set:', str(round(len(strat_test_set.loc[strat_test_set['Class'] == 'Mine'])/len(strat_test_set), 3)))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "share of observations in the train set: 0.697\n",
            "share of observations in the test set: 0.303\n",
            "share of mines in the train set: 0.559\n",
            "share of mines in the test set: 0.556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSqWxbi24D5v"
      },
      "source": [
        "# split features and outcome data\n",
        "X_train = strat_train_set.loc[:,strat_train_set.columns != 'Class']\n",
        "y_train = strat_train_set['Class']\n",
        "X_test = strat_test_set.loc[:,strat_test_set.columns != 'Class']\n",
        "y_test = strat_test_set['Class']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wASW59mlxHa2"
      },
      "source": [
        "## Setting up the pipeline\n",
        "\n",
        "Machine learning is about trial and error, with typically many iterations between different ways to prepare the data (data preparation) and assessing how that translates into performance (model building).\n",
        "\n",
        "Going through different iterations should require the least possible effort, which is done by setting up a pipeline, using sklearn's pipeline functionality. A pipeline explicitly operationalizes all the different steps taken to get from raw data into data prepared and ready to serve as modeling input.\n",
        "\n",
        "\n",
        "As such, the pipeline serves two purposes: \n",
        "- it encompasses every preprocessing step, coded within an overarching Python object, such that it is easily transferred to new data (the raw test data or tomorrow's raw process data). This approach prevents 'manual' adjustments to the data, that would get lost or need to be repeated 'manually' when preparing new data. \n",
        "- it makes it really easy to tweak the preprocessing steps, trying out different ways to prepare the data, requiring minimal adjustment to your code (less time-consuming and less error-prone)\n",
        "\n",
        "Typically, the preprocessing steps include:\n",
        "- selecting the variables\n",
        "- imputing missing values\n",
        "- scaling numeric variables\n",
        "- creating dummy variables for categorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZHs9z1IHwi7"
      },
      "source": [
        "The first thing to realize is that numeric and categorical features require different preprocessing steps, effectively meaning that our overarching pipeline should contain two parallel pipelines: one for preparing numeric features and one for preparing categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZS8TNN8Im9V",
        "outputId": "5de3b543-2344-4a69-95fe-316f96bc9b5c"
      },
      "source": [
        "# dividing the features into numeric and non-numeric\n",
        "num_features = X_train.select_dtypes(include=['float']).columns\n",
        "cat_features = X_train.select_dtypes(exclude=['float']).columns\n",
        "print(num_features)\n",
        "print(cat_features)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['attribute_1', 'attribute_2', 'attribute_3', 'attribute_4',\n",
            "       'attribute_5', 'attribute_6', 'attribute_7', 'attribute_8',\n",
            "       'attribute_9', 'attribute_10', 'attribute_11', 'attribute_12',\n",
            "       'attribute_13', 'attribute_14', 'attribute_15', 'attribute_16',\n",
            "       'attribute_17', 'attribute_18', 'attribute_19', 'attribute_20',\n",
            "       'attribute_21', 'attribute_22', 'attribute_23', 'attribute_24',\n",
            "       'attribute_25', 'attribute_26', 'attribute_27', 'attribute_28',\n",
            "       'attribute_29', 'attribute_30', 'attribute_31', 'attribute_32',\n",
            "       'attribute_33', 'attribute_34', 'attribute_35', 'attribute_36',\n",
            "       'attribute_37', 'attribute_38', 'attribute_39', 'attribute_40',\n",
            "       'attribute_41', 'attribute_42', 'attribute_43', 'attribute_44',\n",
            "       'attribute_45', 'attribute_46', 'attribute_47', 'attribute_48',\n",
            "       'attribute_49', 'attribute_50', 'attribute_51', 'attribute_52',\n",
            "       'attribute_53', 'attribute_54', 'attribute_55', 'attribute_56',\n",
            "       'attribute_57', 'attribute_58', 'attribute_59', 'attribute_60'],\n",
            "      dtype='object')\n",
            "Index(['batch', 'location'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMVKvJXELD41"
      },
      "source": [
        "We will now define a 'numeric pipeline' and a 'categorical pipeline', which is then combined into a 'full pipeline'.\n",
        "\n",
        "We start off with the 'numeric pipeline', containing the steps of imputing missing values, and standardizing the feature values (which is required for specific machine learning algorithms, and speeds up estimation of other models). As the imputation strategy within this pipeline only applies to numeric features, imputation can be straightforwardly applied using median imputation (or comparable methods)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37CxIKPVMT5B"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WUPiNCQiNSg"
      },
      "source": [
        "Let's unpack this part of our pipeline:\n",
        "num_pipeline is now a Pipeline object, which, as you would expect, simply passes on the input it receives through each of the elements of the pipeline. Each element is given a user-defined name, and is accompanied by a specific preprocessing step, which is often a function imported from the sklearn.preprocessing module, but could also be a user-defined function. Each element in the Pipeline can be accessed separately, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAEEojV_jOsT",
        "outputId": "bcfe13f3-6e7b-42c2-8112-1b315cbd5c8d"
      },
      "source": [
        "type(num_pipeline)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.pipeline.Pipeline"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRm6zA5GjSL3",
        "outputId": "6efd4808-637b-42bc-9563-25fc766ba19c"
      },
      "source": [
        "num_pipeline"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('std_scaler', StandardScaler())])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9gCmSHjXwc"
      },
      "source": [
        "Each functionality can be accessed individually as follows:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSPircvQkApB",
        "outputId": "3640fcd2-0c97-485d-ce95-fdbff503948f"
      },
      "source": [
        "num_pipeline['imputer']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(strategy='median')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg88owwjkMAX"
      },
      "source": [
        "Just as we saw above, this preprocessing functionality can be used to transform data, but it needs to be fitted on data first (or it can be done simultaneously). Once we fit the num_pipeline to our numerical training data, it will contain medians to be imputed and scaling factors to be applied, making it possible to use the pipeline for transforming data according to these preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "gncOglbakGLs",
        "outputId": "c758a589-0899-468d-bad7-281e7b42e643"
      },
      "source": [
        "# transforming will give an error, until the pipeline is being fitted (as stated in the NotFittedError below)\n",
        "num_pipeline.transform(X_train[num_features])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5025c0c2f778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transforming will give an error, until the pipeline is being fitted (as stated in the NotFittedError below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mimputed\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SimpleImputer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCJwS0ZymbWe",
        "outputId": "687fd732-acc3-4e33-b471-da2f00e21163"
      },
      "source": [
        "# transforming will give an error, until the pipeline is being fitted (as stated in the NotFittedError below)\n",
        "num_pipeline.fit(X_train[num_features])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
              "                ('std_scaler', StandardScaler())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqwGekRmnzi"
      },
      "source": [
        "Now the imputer and standard scaler do contain fitted statistics that can be applied to transform data according to these preprocessing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Yl6EGVmhep",
        "outputId": "ef4bc6b3-cddd-4422-fb40-e8fb1b7bfde6"
      },
      "source": [
        "# the statistics_ for the imputer step contains the medians to be used for imputation\n",
        "num_pipeline['imputer'].statistics_"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.0228 , 0.02925, 0.038  , 0.0454 , 0.06105, 0.0932 , 0.1122 ,\n",
              "       0.113  , 0.1553 , 0.18705, 0.2373 , 0.2551 , 0.27065, 0.2976 ,\n",
              "       0.3039 , 0.3047 , 0.3068 , 0.3771 , 0.4433 , 0.5425 , 0.6496 ,\n",
              "       0.6628 , 0.7052 , 0.69325, 0.72775, 0.7545 , 0.7654 , 0.7321 ,\n",
              "       0.634  , 0.6005 , 0.492  , 0.4241 , 0.3897 , 0.3682 , 0.3369 ,\n",
              "       0.31035, 0.2821 , 0.315  , 0.28905, 0.2883 , 0.2609 , 0.2633 ,\n",
              "       0.2207 , 0.1755 , 0.14955, 0.12785, 0.0947 , 0.08055, 0.049  ,\n",
              "       0.0179 , 0.014  , 0.0115 , 0.00865, 0.0093 , 0.0075 , 0.0065 ,\n",
              "       0.0057 , 0.0058 , 0.0069 , 0.0048 ])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xKEQwyBinPPh",
        "outputId": "764065c4-618f-4f57-c81c-3447619d99cd"
      },
      "source": [
        "# the statistics of the standardscaler are the mean and std\n",
        "means = num_pipeline['std_scaler'].mean_\n",
        "scale = num_pipeline['std_scaler'].scale_\n",
        "pd.DataFrame({'Means':means, 'Scale':scale}, index=X_train[num_features].columns)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b7d363c-12c0-43a1-a126-3fc1142506c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Means</th>\n",
              "      <th>Scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>attribute_1</th>\n",
              "      <td>0.030316</td>\n",
              "      <td>0.024040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_2</th>\n",
              "      <td>0.038669</td>\n",
              "      <td>0.035053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_3</th>\n",
              "      <td>0.047230</td>\n",
              "      <td>0.041599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_4</th>\n",
              "      <td>0.057621</td>\n",
              "      <td>0.050468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_5</th>\n",
              "      <td>0.074851</td>\n",
              "      <td>0.055196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_6</th>\n",
              "      <td>0.101849</td>\n",
              "      <td>0.048008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_7</th>\n",
              "      <td>0.126627</td>\n",
              "      <td>0.063411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_8</th>\n",
              "      <td>0.136208</td>\n",
              "      <td>0.085086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_9</th>\n",
              "      <td>0.183074</td>\n",
              "      <td>0.117458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_10</th>\n",
              "      <td>0.215243</td>\n",
              "      <td>0.135830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_11</th>\n",
              "      <td>0.248950</td>\n",
              "      <td>0.125070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_12</th>\n",
              "      <td>0.256374</td>\n",
              "      <td>0.132509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_13</th>\n",
              "      <td>0.283613</td>\n",
              "      <td>0.126429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_14</th>\n",
              "      <td>0.310881</td>\n",
              "      <td>0.160377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_15</th>\n",
              "      <td>0.341880</td>\n",
              "      <td>0.194530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_16</th>\n",
              "      <td>0.371477</td>\n",
              "      <td>0.222879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_17</th>\n",
              "      <td>0.418797</td>\n",
              "      <td>0.265304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_18</th>\n",
              "      <td>0.458043</td>\n",
              "      <td>0.254017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_19</th>\n",
              "      <td>0.505872</td>\n",
              "      <td>0.256024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_20</th>\n",
              "      <td>0.555277</td>\n",
              "      <td>0.248828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_21</th>\n",
              "      <td>0.609820</td>\n",
              "      <td>0.247246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_22</th>\n",
              "      <td>0.624209</td>\n",
              "      <td>0.251237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_23</th>\n",
              "      <td>0.654730</td>\n",
              "      <td>0.238628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_24</th>\n",
              "      <td>0.678239</td>\n",
              "      <td>0.229609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_25</th>\n",
              "      <td>0.682419</td>\n",
              "      <td>0.229040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_26</th>\n",
              "      <td>0.712124</td>\n",
              "      <td>0.224476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_27</th>\n",
              "      <td>0.723590</td>\n",
              "      <td>0.226149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_28</th>\n",
              "      <td>0.700014</td>\n",
              "      <td>0.215167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_29</th>\n",
              "      <td>0.630289</td>\n",
              "      <td>0.231767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_30</th>\n",
              "      <td>0.580569</td>\n",
              "      <td>0.199783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_31</th>\n",
              "      <td>0.505533</td>\n",
              "      <td>0.201870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_32</th>\n",
              "      <td>0.434770</td>\n",
              "      <td>0.203157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_33</th>\n",
              "      <td>0.412819</td>\n",
              "      <td>0.196230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_34</th>\n",
              "      <td>0.396540</td>\n",
              "      <td>0.221638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_35</th>\n",
              "      <td>0.368626</td>\n",
              "      <td>0.225584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_36</th>\n",
              "      <td>0.373233</td>\n",
              "      <td>0.255737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_37</th>\n",
              "      <td>0.349441</td>\n",
              "      <td>0.235093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_38</th>\n",
              "      <td>0.345731</td>\n",
              "      <td>0.211585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_39</th>\n",
              "      <td>0.322130</td>\n",
              "      <td>0.187913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_40</th>\n",
              "      <td>0.314211</td>\n",
              "      <td>0.168741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_41</th>\n",
              "      <td>0.292407</td>\n",
              "      <td>0.159929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_42</th>\n",
              "      <td>0.283801</td>\n",
              "      <td>0.161344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_43</th>\n",
              "      <td>0.243272</td>\n",
              "      <td>0.132807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_44</th>\n",
              "      <td>0.210315</td>\n",
              "      <td>0.129146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_45</th>\n",
              "      <td>0.186814</td>\n",
              "      <td>0.144599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_46</th>\n",
              "      <td>0.161016</td>\n",
              "      <td>0.126471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_47</th>\n",
              "      <td>0.117938</td>\n",
              "      <td>0.086613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_48</th>\n",
              "      <td>0.093636</td>\n",
              "      <td>0.063992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_49</th>\n",
              "      <td>0.054905</td>\n",
              "      <td>0.036116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_50</th>\n",
              "      <td>0.020219</td>\n",
              "      <td>0.012895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_51</th>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.011761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_52</th>\n",
              "      <td>0.013355</td>\n",
              "      <td>0.009462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_53</th>\n",
              "      <td>0.009907</td>\n",
              "      <td>0.006221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_54</th>\n",
              "      <td>0.010981</td>\n",
              "      <td>0.007202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_55</th>\n",
              "      <td>0.009450</td>\n",
              "      <td>0.007024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_56</th>\n",
              "      <td>0.007970</td>\n",
              "      <td>0.005882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_57</th>\n",
              "      <td>0.007569</td>\n",
              "      <td>0.005725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_58</th>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.006671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_59</th>\n",
              "      <td>0.008344</td>\n",
              "      <td>0.006434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_60</th>\n",
              "      <td>0.005890</td>\n",
              "      <td>0.004134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b7d363c-12c0-43a1-a126-3fc1142506c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b7d363c-12c0-43a1-a126-3fc1142506c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b7d363c-12c0-43a1-a126-3fc1142506c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Means     Scale\n",
              "attribute_1   0.030316  0.024040\n",
              "attribute_2   0.038669  0.035053\n",
              "attribute_3   0.047230  0.041599\n",
              "attribute_4   0.057621  0.050468\n",
              "attribute_5   0.074851  0.055196\n",
              "attribute_6   0.101849  0.048008\n",
              "attribute_7   0.126627  0.063411\n",
              "attribute_8   0.136208  0.085086\n",
              "attribute_9   0.183074  0.117458\n",
              "attribute_10  0.215243  0.135830\n",
              "attribute_11  0.248950  0.125070\n",
              "attribute_12  0.256374  0.132509\n",
              "attribute_13  0.283613  0.126429\n",
              "attribute_14  0.310881  0.160377\n",
              "attribute_15  0.341880  0.194530\n",
              "attribute_16  0.371477  0.222879\n",
              "attribute_17  0.418797  0.265304\n",
              "attribute_18  0.458043  0.254017\n",
              "attribute_19  0.505872  0.256024\n",
              "attribute_20  0.555277  0.248828\n",
              "attribute_21  0.609820  0.247246\n",
              "attribute_22  0.624209  0.251237\n",
              "attribute_23  0.654730  0.238628\n",
              "attribute_24  0.678239  0.229609\n",
              "attribute_25  0.682419  0.229040\n",
              "attribute_26  0.712124  0.224476\n",
              "attribute_27  0.723590  0.226149\n",
              "attribute_28  0.700014  0.215167\n",
              "attribute_29  0.630289  0.231767\n",
              "attribute_30  0.580569  0.199783\n",
              "attribute_31  0.505533  0.201870\n",
              "attribute_32  0.434770  0.203157\n",
              "attribute_33  0.412819  0.196230\n",
              "attribute_34  0.396540  0.221638\n",
              "attribute_35  0.368626  0.225584\n",
              "attribute_36  0.373233  0.255737\n",
              "attribute_37  0.349441  0.235093\n",
              "attribute_38  0.345731  0.211585\n",
              "attribute_39  0.322130  0.187913\n",
              "attribute_40  0.314211  0.168741\n",
              "attribute_41  0.292407  0.159929\n",
              "attribute_42  0.283801  0.161344\n",
              "attribute_43  0.243272  0.132807\n",
              "attribute_44  0.210315  0.129146\n",
              "attribute_45  0.186814  0.144599\n",
              "attribute_46  0.161016  0.126471\n",
              "attribute_47  0.117938  0.086613\n",
              "attribute_48  0.093636  0.063992\n",
              "attribute_49  0.054905  0.036116\n",
              "attribute_50  0.020219  0.012895\n",
              "attribute_51  0.015806  0.011761\n",
              "attribute_52  0.013355  0.009462\n",
              "attribute_53  0.009907  0.006221\n",
              "attribute_54  0.010981  0.007202\n",
              "attribute_55  0.009450  0.007024\n",
              "attribute_56  0.007970  0.005882\n",
              "attribute_57  0.007569  0.005725\n",
              "attribute_58  0.007968  0.006671\n",
              "attribute_59  0.008344  0.006434\n",
              "attribute_60  0.005890  0.004134"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsfsHJnOqyfH"
      },
      "source": [
        "Now that the imputer and standard scaler have been fitted, we can use it to transform the numerical train data, and check whether it indeed results in fully imputed, fully scaled data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIKbhWjPrOtw",
        "outputId": "7cbb1558-4e16-4da5-9a73-5df35f516583"
      },
      "source": [
        "X_num_prep = num_pipeline.transform(X_train[num_features])\n",
        "X_num_prep"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.92694488,  0.50297168,  1.79499411, ...,  0.34962688,\n",
              "         4.36066979,  3.60663451],\n",
              "       [-0.13792866, -0.63815596, -0.31562267, ...,  0.21471763,\n",
              "         0.33508158,  0.82479305],\n",
              "       [-0.18784461,  0.1321052 ,  0.17957899, ..., -0.24996978,\n",
              "        -0.55085868, -0.21537375],\n",
              "       ...,\n",
              "       [-0.30847482, -0.05047522, -1.03919403, ..., -0.75962693,\n",
              "         0.31953877, -0.2637536 ],\n",
              "       [-0.74939902, -1.04040346, -0.66418695, ..., -0.32491936,\n",
              "        -0.56640149,  0.29261469],\n",
              "       [-0.88666787, -0.92629069, -0.2218709 , ..., -0.39986894,\n",
              "         1.64067776, -0.2637536 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPTO8StNr2Rm"
      },
      "source": [
        "You see that the pipeline has the typically undesired feature (though it does speed up computing time) of removing the column names. It is good practice to keep track of the column names, which becomes even more important when we apply preprocessing steps that will change the number of features that we have, as we will encounter when preprocessing the categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "m5JAka5EtEIr",
        "outputId": "c50ef6cb-59cf-4d44-8b92-65665c1c1575"
      },
      "source": [
        "X_num_prep = pd.DataFrame(X_num_prep, columns=X_train[num_features].columns)\n",
        "X_num_prep.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7db817d-95a5-489e-ae69-6fb4dc010bc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.926945</td>\n",
              "      <td>0.502972</td>\n",
              "      <td>1.794994</td>\n",
              "      <td>1.247895</td>\n",
              "      <td>-0.910411</td>\n",
              "      <td>0.007312</td>\n",
              "      <td>-0.227513</td>\n",
              "      <td>-1.084874</td>\n",
              "      <td>0.391854</td>\n",
              "      <td>-0.383149</td>\n",
              "      <td>0.043578</td>\n",
              "      <td>0.183576</td>\n",
              "      <td>0.138311</td>\n",
              "      <td>0.157250</td>\n",
              "      <td>-0.202950</td>\n",
              "      <td>-0.641501</td>\n",
              "      <td>-0.481701</td>\n",
              "      <td>-0.318653</td>\n",
              "      <td>-1.526312</td>\n",
              "      <td>-0.863553</td>\n",
              "      <td>-0.216869</td>\n",
              "      <td>0.054494</td>\n",
              "      <td>0.002387</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>-0.126698</td>\n",
              "      <td>-0.756537</td>\n",
              "      <td>-0.158699</td>\n",
              "      <td>0.149119</td>\n",
              "      <td>0.614025</td>\n",
              "      <td>1.212968</td>\n",
              "      <td>1.848547</td>\n",
              "      <td>2.343166</td>\n",
              "      <td>1.313158</td>\n",
              "      <td>0.959491</td>\n",
              "      <td>1.692826</td>\n",
              "      <td>0.407710</td>\n",
              "      <td>-0.777738</td>\n",
              "      <td>0.137859</td>\n",
              "      <td>-0.176039</td>\n",
              "      <td>-0.614025</td>\n",
              "      <td>1.852024</td>\n",
              "      <td>1.729214</td>\n",
              "      <td>0.108635</td>\n",
              "      <td>2.432785</td>\n",
              "      <td>2.960505</td>\n",
              "      <td>2.777579</td>\n",
              "      <td>2.546510</td>\n",
              "      <td>0.879237</td>\n",
              "      <td>-0.008440</td>\n",
              "      <td>0.525834</td>\n",
              "      <td>1.887135</td>\n",
              "      <td>2.171228</td>\n",
              "      <td>0.802669</td>\n",
              "      <td>3.127028</td>\n",
              "      <td>4.007493</td>\n",
              "      <td>1.603111</td>\n",
              "      <td>0.983535</td>\n",
              "      <td>0.349627</td>\n",
              "      <td>4.360670</td>\n",
              "      <td>3.606635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137929</td>\n",
              "      <td>-0.638156</td>\n",
              "      <td>-0.315623</td>\n",
              "      <td>-0.652323</td>\n",
              "      <td>0.133136</td>\n",
              "      <td>0.494733</td>\n",
              "      <td>0.089465</td>\n",
              "      <td>0.260823</td>\n",
              "      <td>0.158578</td>\n",
              "      <td>-0.022404</td>\n",
              "      <td>-0.223472</td>\n",
              "      <td>-0.124327</td>\n",
              "      <td>-0.102535</td>\n",
              "      <td>0.593721</td>\n",
              "      <td>0.861665</td>\n",
              "      <td>0.806368</td>\n",
              "      <td>0.914055</td>\n",
              "      <td>0.875360</td>\n",
              "      <td>0.570761</td>\n",
              "      <td>0.496420</td>\n",
              "      <td>0.692751</td>\n",
              "      <td>0.846574</td>\n",
              "      <td>1.014841</td>\n",
              "      <td>1.338627</td>\n",
              "      <td>1.386574</td>\n",
              "      <td>1.012920</td>\n",
              "      <td>0.184880</td>\n",
              "      <td>0.513488</td>\n",
              "      <td>0.226568</td>\n",
              "      <td>-0.116971</td>\n",
              "      <td>-0.373671</td>\n",
              "      <td>-0.496511</td>\n",
              "      <td>-0.117814</td>\n",
              "      <td>-1.429086</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>-0.863126</td>\n",
              "      <td>-0.369389</td>\n",
              "      <td>-0.473242</td>\n",
              "      <td>-0.660572</td>\n",
              "      <td>-0.153555</td>\n",
              "      <td>-0.322060</td>\n",
              "      <td>-0.580755</td>\n",
              "      <td>-0.267850</td>\n",
              "      <td>-0.260288</td>\n",
              "      <td>-0.518082</td>\n",
              "      <td>-0.657188</td>\n",
              "      <td>-0.268295</td>\n",
              "      <td>0.036939</td>\n",
              "      <td>0.135541</td>\n",
              "      <td>0.991127</td>\n",
              "      <td>0.331137</td>\n",
              "      <td>-0.196059</td>\n",
              "      <td>1.686764</td>\n",
              "      <td>-0.344468</td>\n",
              "      <td>-0.733223</td>\n",
              "      <td>0.209051</td>\n",
              "      <td>1.088333</td>\n",
              "      <td>0.214718</td>\n",
              "      <td>0.335082</td>\n",
              "      <td>0.824793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.187845</td>\n",
              "      <td>0.132105</td>\n",
              "      <td>0.179579</td>\n",
              "      <td>0.207629</td>\n",
              "      <td>-0.250042</td>\n",
              "      <td>0.482235</td>\n",
              "      <td>0.046886</td>\n",
              "      <td>0.431239</td>\n",
              "      <td>0.820094</td>\n",
              "      <td>0.590127</td>\n",
              "      <td>0.013195</td>\n",
              "      <td>0.028115</td>\n",
              "      <td>-0.464397</td>\n",
              "      <td>-0.619668</td>\n",
              "      <td>-1.104609</td>\n",
              "      <td>-1.131452</td>\n",
              "      <td>-0.902350</td>\n",
              "      <td>-0.943020</td>\n",
              "      <td>-1.332970</td>\n",
              "      <td>-1.934171</td>\n",
              "      <td>-2.213663</td>\n",
              "      <td>-1.536829</td>\n",
              "      <td>-0.722171</td>\n",
              "      <td>-0.178734</td>\n",
              "      <td>0.308597</td>\n",
              "      <td>0.818689</td>\n",
              "      <td>1.196162</td>\n",
              "      <td>1.374217</td>\n",
              "      <td>1.305235</td>\n",
              "      <td>1.771073</td>\n",
              "      <td>1.881736</td>\n",
              "      <td>-0.052519</td>\n",
              "      <td>1.394695</td>\n",
              "      <td>1.093945</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>1.132673</td>\n",
              "      <td>1.058557</td>\n",
              "      <td>0.523519</td>\n",
              "      <td>-0.176039</td>\n",
              "      <td>0.602042</td>\n",
              "      <td>-0.197005</td>\n",
              "      <td>0.739405</td>\n",
              "      <td>1.331459</td>\n",
              "      <td>1.900056</td>\n",
              "      <td>-0.257707</td>\n",
              "      <td>1.072056</td>\n",
              "      <td>1.057134</td>\n",
              "      <td>0.971437</td>\n",
              "      <td>0.927435</td>\n",
              "      <td>0.487060</td>\n",
              "      <td>-0.315070</td>\n",
              "      <td>-0.449697</td>\n",
              "      <td>-0.595808</td>\n",
              "      <td>-1.260943</td>\n",
              "      <td>-0.277659</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.780564</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.215374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.778517</td>\n",
              "      <td>-0.592511</td>\n",
              "      <td>-0.056002</td>\n",
              "      <td>1.029934</td>\n",
              "      <td>2.109716</td>\n",
              "      <td>-0.196821</td>\n",
              "      <td>-0.796811</td>\n",
              "      <td>-0.317415</td>\n",
              "      <td>-0.914150</td>\n",
              "      <td>-0.844020</td>\n",
              "      <td>0.008398</td>\n",
              "      <td>1.074835</td>\n",
              "      <td>0.769494</td>\n",
              "      <td>1.025204</td>\n",
              "      <td>1.411707</td>\n",
              "      <td>1.233505</td>\n",
              "      <td>1.445897</td>\n",
              "      <td>1.821751</td>\n",
              "      <td>1.864392</td>\n",
              "      <td>1.640181</td>\n",
              "      <td>1.030471</td>\n",
              "      <td>0.829061</td>\n",
              "      <td>0.724431</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>-0.315311</td>\n",
              "      <td>-1.010462</td>\n",
              "      <td>-1.273895</td>\n",
              "      <td>-1.251656</td>\n",
              "      <td>-0.821466</td>\n",
              "      <td>-0.987414</td>\n",
              "      <td>-1.002292</td>\n",
              "      <td>-0.646149</td>\n",
              "      <td>-0.474538</td>\n",
              "      <td>-0.755014</td>\n",
              "      <td>-0.689435</td>\n",
              "      <td>-0.245891</td>\n",
              "      <td>-0.124805</td>\n",
              "      <td>0.471531</td>\n",
              "      <td>0.230799</td>\n",
              "      <td>-0.253116</td>\n",
              "      <td>-0.735993</td>\n",
              "      <td>-0.655130</td>\n",
              "      <td>-0.175987</td>\n",
              "      <td>-0.810827</td>\n",
              "      <td>-0.895678</td>\n",
              "      <td>-1.030395</td>\n",
              "      <td>-1.088029</td>\n",
              "      <td>-0.728787</td>\n",
              "      <td>-1.237815</td>\n",
              "      <td>-1.125955</td>\n",
              "      <td>-1.080315</td>\n",
              "      <td>0.311217</td>\n",
              "      <td>-0.001053</td>\n",
              "      <td>-0.358354</td>\n",
              "      <td>2.498437</td>\n",
              "      <td>3.354188</td>\n",
              "      <td>0.372213</td>\n",
              "      <td>-0.384879</td>\n",
              "      <td>-0.224460</td>\n",
              "      <td>0.800603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.587172</td>\n",
              "      <td>-0.381402</td>\n",
              "      <td>-0.505530</td>\n",
              "      <td>-0.376901</td>\n",
              "      <td>-0.187537</td>\n",
              "      <td>-1.138334</td>\n",
              "      <td>-0.331595</td>\n",
              "      <td>0.030468</td>\n",
              "      <td>-0.236458</td>\n",
              "      <td>-0.602542</td>\n",
              "      <td>0.383387</td>\n",
              "      <td>1.652909</td>\n",
              "      <td>-0.102535</td>\n",
              "      <td>1.609451</td>\n",
              "      <td>-0.195239</td>\n",
              "      <td>-0.299612</td>\n",
              "      <td>1.813400</td>\n",
              "      <td>2.133541</td>\n",
              "      <td>1.808929</td>\n",
              "      <td>1.398247</td>\n",
              "      <td>0.641789</td>\n",
              "      <td>0.153604</td>\n",
              "      <td>0.040522</td>\n",
              "      <td>-0.356427</td>\n",
              "      <td>-1.359233</td>\n",
              "      <td>-2.762099</td>\n",
              "      <td>-2.986928</td>\n",
              "      <td>-2.846234</td>\n",
              "      <td>-2.270763</td>\n",
              "      <td>-2.048062</td>\n",
              "      <td>-0.887367</td>\n",
              "      <td>0.130098</td>\n",
              "      <td>-0.096410</td>\n",
              "      <td>0.489356</td>\n",
              "      <td>0.508345</td>\n",
              "      <td>-0.245891</td>\n",
              "      <td>-0.499976</td>\n",
              "      <td>-0.145242</td>\n",
              "      <td>0.241974</td>\n",
              "      <td>-0.967230</td>\n",
              "      <td>-1.362519</td>\n",
              "      <td>-0.894370</td>\n",
              "      <td>-0.663159</td>\n",
              "      <td>-1.336588</td>\n",
              "      <td>-0.257707</td>\n",
              "      <td>-0.262237</td>\n",
              "      <td>-1.056856</td>\n",
              "      <td>-1.114775</td>\n",
              "      <td>-1.002462</td>\n",
              "      <td>-0.970857</td>\n",
              "      <td>-0.179026</td>\n",
              "      <td>-0.661062</td>\n",
              "      <td>-0.274319</td>\n",
              "      <td>1.696771</td>\n",
              "      <td>1.473417</td>\n",
              "      <td>-0.096963</td>\n",
              "      <td>-0.326440</td>\n",
              "      <td>0.304657</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.965261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7db817d-95a5-489e-ae69-6fb4dc010bc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7db817d-95a5-489e-ae69-6fb4dc010bc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7db817d-95a5-489e-ae69-6fb4dc010bc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   attribute_1  attribute_2  ...  attribute_59  attribute_60\n",
              "0     0.926945     0.502972  ...      4.360670      3.606635\n",
              "1    -0.137929    -0.638156  ...      0.335082      0.824793\n",
              "2    -0.187845     0.132105  ...     -0.550859     -0.215374\n",
              "3    -0.778517    -0.592511  ...     -0.224460      0.800603\n",
              "4    -0.587172    -0.381402  ...     -0.550859     -0.965261\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgqLIKxrtR16",
        "outputId": "a20fa6a3-1ee4-48e5-a249-1a6b27d101fe"
      },
      "source": [
        "# every missing has been imputed\n",
        "sum(X_num_prep.isnull().sum())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R-FMfZb-tppr",
        "outputId": "ef099d49-4f82-4dc1-9435-4c42701a2446"
      },
      "source": [
        "# every mean is 0; every standard deviation is 1\n",
        "mean = X_num_prep.mean(axis=0).round(3)\n",
        "std = X_num_prep.std(axis=0).round(3)\n",
        "pd.DataFrame({'Prepped_Means':mean, 'Prepped_Scale':std}, index=X_train[num_features].columns)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6de50194-6d65-47ae-950c-deecf8b61c39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prepped_Means</th>\n",
              "      <th>Prepped_Scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>attribute_1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_2</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_6</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_7</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_8</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_9</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_10</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_13</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_14</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_18</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_20</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_24</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_30</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_31</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_32</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_33</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_34</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_35</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_36</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_37</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_38</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_39</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_41</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_42</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_43</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_44</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_45</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_46</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_47</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_48</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_49</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_50</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_51</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_52</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_53</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_54</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_55</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_56</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_57</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_58</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_59</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attribute_60</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6de50194-6d65-47ae-950c-deecf8b61c39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6de50194-6d65-47ae-950c-deecf8b61c39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6de50194-6d65-47ae-950c-deecf8b61c39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              Prepped_Means  Prepped_Scale\n",
              "attribute_1             0.0          1.003\n",
              "attribute_2            -0.0          1.003\n",
              "attribute_3             0.0          1.003\n",
              "attribute_4             0.0          1.003\n",
              "attribute_5             0.0          1.003\n",
              "attribute_6            -0.0          1.003\n",
              "attribute_7            -0.0          1.003\n",
              "attribute_8            -0.0          1.003\n",
              "attribute_9            -0.0          1.003\n",
              "attribute_10           -0.0          1.003\n",
              "attribute_11            0.0          1.003\n",
              "attribute_12            0.0          1.003\n",
              "attribute_13           -0.0          1.003\n",
              "attribute_14           -0.0          1.003\n",
              "attribute_15            0.0          1.003\n",
              "attribute_16            0.0          1.003\n",
              "attribute_17            0.0          1.003\n",
              "attribute_18           -0.0          1.003\n",
              "attribute_19            0.0          1.003\n",
              "attribute_20           -0.0          1.003\n",
              "attribute_21            0.0          1.003\n",
              "attribute_22            0.0          1.003\n",
              "attribute_23            0.0          1.003\n",
              "attribute_24           -0.0          1.003\n",
              "attribute_25            0.0          1.003\n",
              "attribute_26            0.0          1.003\n",
              "attribute_27            0.0          1.003\n",
              "attribute_28            0.0          1.003\n",
              "attribute_29            0.0          1.003\n",
              "attribute_30           -0.0          1.003\n",
              "attribute_31            0.0          1.003\n",
              "attribute_32           -0.0          1.003\n",
              "attribute_33           -0.0          1.003\n",
              "attribute_34           -0.0          1.003\n",
              "attribute_35           -0.0          1.003\n",
              "attribute_36            0.0          1.003\n",
              "attribute_37           -0.0          1.003\n",
              "attribute_38            0.0          1.003\n",
              "attribute_39            0.0          1.003\n",
              "attribute_40            0.0          1.003\n",
              "attribute_41            0.0          1.003\n",
              "attribute_42           -0.0          1.003\n",
              "attribute_43           -0.0          1.003\n",
              "attribute_44           -0.0          1.003\n",
              "attribute_45           -0.0          1.003\n",
              "attribute_46           -0.0          1.003\n",
              "attribute_47            0.0          1.003\n",
              "attribute_48            0.0          1.003\n",
              "attribute_49           -0.0          1.003\n",
              "attribute_50           -0.0          1.003\n",
              "attribute_51           -0.0          1.003\n",
              "attribute_52           -0.0          1.003\n",
              "attribute_53           -0.0          1.003\n",
              "attribute_54           -0.0          1.003\n",
              "attribute_55           -0.0          1.003\n",
              "attribute_56           -0.0          1.003\n",
              "attribute_57           -0.0          1.003\n",
              "attribute_58           -0.0          1.003\n",
              "attribute_59           -0.0          1.003\n",
              "attribute_60           -0.0          1.003"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wnXd1rOwXOv"
      },
      "source": [
        "### Categorical preprocessing\n",
        "\n",
        "We took very small steps when walking through the numeric preprocessing pipeline. Now that we have seen the general principles, we will go through the categorical preprocessing pipeline more quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrBYJ-UwwWhm"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "        ('cat_imputer', SimpleImputer(strategy = 'most_frequent')),\n",
        "        ('cat_encoder', OneHotEncoder(sparse=False))])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQx6XYu2jOH",
        "outputId": "5d5b8cc8-180b-4288-c042-14e316b5a226"
      },
      "source": [
        "cat_pipeline.fit(X_train[cat_features])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
              "                ('cat_encoder', OneHotEncoder(sparse=False))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz1LHJtm2sTP",
        "outputId": "e0709108-60c9-4246-cd34-3d840a410b47"
      },
      "source": [
        "cat_pipeline['cat_imputer'].statistics_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['third', 'loc_E'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi0BiNs85DXG"
      },
      "source": [
        "X_cat_prep = cat_pipeline.transform(X_train[cat_features])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi5yeexx5iV8"
      },
      "source": [
        "As the code below shows, our prepared data now contains 8 columns, while we started with 2 categorical features. This is due to the OneHotEncoder transforming the two categorical features (containing 3, and 5 levels) into 1 feature per level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAp_j8ZC5PYj",
        "outputId": "6730add7-2e98-452c-97d7-484c2984fdda"
      },
      "source": [
        "X_cat_prep.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6J9qSpe7oyD"
      },
      "source": [
        "Feature names of these 8 variables are easily accessed through:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y41D8BDh7tKi",
        "outputId": "61c8f6ad-58b1-4b3b-bc1d-9ca886e94302"
      },
      "source": [
        "cat_pipeline['cat_encoder'].get_feature_names(cat_features)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['batch_first', 'batch_second', 'batch_third', 'location_loc_A',\n",
              "       'location_loc_B', 'location_loc_C', 'location_loc_D',\n",
              "       'location_loc_E'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkqDK4A8MxT"
      },
      "source": [
        "Such that we could add those to the numpy array, to better keep track of what is happening to the data while preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "KC-7ObFy8Zds",
        "outputId": "7809d45c-251a-4b0f-9204-241fa7407ecf"
      },
      "source": [
        "cat_names = cat_pipeline['cat_encoder'].get_feature_names(cat_features)\n",
        "pd.DataFrame(X_cat_prep, columns = cat_names).head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4a4aeadd-84c1-47e2-81c4-6dce99d91f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a4aeadd-84c1-47e2-81c4-6dce99d91f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a4aeadd-84c1-47e2-81c4-6dce99d91f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a4aeadd-84c1-47e2-81c4-6dce99d91f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   batch_first  batch_second  ...  location_loc_D  location_loc_E\n",
              "0          0.0           0.0  ...             0.0             1.0\n",
              "1          0.0           0.0  ...             0.0             1.0\n",
              "2          0.0           0.0  ...             0.0             1.0\n",
              "3          0.0           1.0  ...             1.0             0.0\n",
              "4          0.0           1.0  ...             1.0             0.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWNUKG_v9CtJ"
      },
      "source": [
        "### Full Pipeline\n",
        "\n",
        "Now that we have constructed the numeric and categorical pipeline, we can define the full pipeline, simply as being a combination of both pipelines, wrapped in a ColumnTransformer, which allows for different subsets of features to be transformed differently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TSGy1OQ9bWm"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_features),\n",
        "        (\"cat\", cat_pipeline, cat_features)])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5-yVLgtAm8t"
      },
      "source": [
        "By applying the fit_transform functionality, this could be applied straight away to the raw data and end up with our fully prepared data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "n-CbifgwBrBJ",
        "outputId": "291e0240-2636-426c-add6-2d4764388572"
      },
      "source": [
        "X_train_prep = full_pipeline.fit_transform(X_train)\n",
        "pd.DataFrame(X_train_prep, columns=[num_features.tolist() + cat_names.tolist()]).head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c732ca66-9558-4255-90fb-4d020d8463d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.926945</td>\n",
              "      <td>0.502972</td>\n",
              "      <td>1.794994</td>\n",
              "      <td>1.247895</td>\n",
              "      <td>-0.910411</td>\n",
              "      <td>0.007312</td>\n",
              "      <td>-0.227513</td>\n",
              "      <td>-1.084874</td>\n",
              "      <td>0.391854</td>\n",
              "      <td>-0.383149</td>\n",
              "      <td>0.043578</td>\n",
              "      <td>0.183576</td>\n",
              "      <td>0.138311</td>\n",
              "      <td>0.157250</td>\n",
              "      <td>-0.202950</td>\n",
              "      <td>-0.641501</td>\n",
              "      <td>-0.481701</td>\n",
              "      <td>-0.318653</td>\n",
              "      <td>-1.526312</td>\n",
              "      <td>-0.863553</td>\n",
              "      <td>-0.216869</td>\n",
              "      <td>0.054494</td>\n",
              "      <td>0.002387</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>-0.126698</td>\n",
              "      <td>-0.756537</td>\n",
              "      <td>-0.158699</td>\n",
              "      <td>0.149119</td>\n",
              "      <td>0.614025</td>\n",
              "      <td>1.212968</td>\n",
              "      <td>1.848547</td>\n",
              "      <td>2.343166</td>\n",
              "      <td>1.313158</td>\n",
              "      <td>0.959491</td>\n",
              "      <td>1.692826</td>\n",
              "      <td>0.407710</td>\n",
              "      <td>-0.777738</td>\n",
              "      <td>0.137859</td>\n",
              "      <td>-0.176039</td>\n",
              "      <td>-0.614025</td>\n",
              "      <td>1.852024</td>\n",
              "      <td>1.729214</td>\n",
              "      <td>0.108635</td>\n",
              "      <td>2.432785</td>\n",
              "      <td>2.960505</td>\n",
              "      <td>2.777579</td>\n",
              "      <td>2.546510</td>\n",
              "      <td>0.879237</td>\n",
              "      <td>-0.008440</td>\n",
              "      <td>0.525834</td>\n",
              "      <td>1.887135</td>\n",
              "      <td>2.171228</td>\n",
              "      <td>0.802669</td>\n",
              "      <td>3.127028</td>\n",
              "      <td>4.007493</td>\n",
              "      <td>1.603111</td>\n",
              "      <td>0.983535</td>\n",
              "      <td>0.349627</td>\n",
              "      <td>4.360670</td>\n",
              "      <td>3.606635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137929</td>\n",
              "      <td>-0.638156</td>\n",
              "      <td>-0.315623</td>\n",
              "      <td>-0.652323</td>\n",
              "      <td>0.133136</td>\n",
              "      <td>0.494733</td>\n",
              "      <td>0.089465</td>\n",
              "      <td>0.260823</td>\n",
              "      <td>0.158578</td>\n",
              "      <td>-0.022404</td>\n",
              "      <td>-0.223472</td>\n",
              "      <td>-0.124327</td>\n",
              "      <td>-0.102535</td>\n",
              "      <td>0.593721</td>\n",
              "      <td>0.861665</td>\n",
              "      <td>0.806368</td>\n",
              "      <td>0.914055</td>\n",
              "      <td>0.875360</td>\n",
              "      <td>0.570761</td>\n",
              "      <td>0.496420</td>\n",
              "      <td>0.692751</td>\n",
              "      <td>0.846574</td>\n",
              "      <td>1.014841</td>\n",
              "      <td>1.338627</td>\n",
              "      <td>1.386574</td>\n",
              "      <td>1.012920</td>\n",
              "      <td>0.184880</td>\n",
              "      <td>0.513488</td>\n",
              "      <td>0.226568</td>\n",
              "      <td>-0.116971</td>\n",
              "      <td>-0.373671</td>\n",
              "      <td>-0.496511</td>\n",
              "      <td>-0.117814</td>\n",
              "      <td>-1.429086</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>-0.863126</td>\n",
              "      <td>-0.369389</td>\n",
              "      <td>-0.473242</td>\n",
              "      <td>-0.660572</td>\n",
              "      <td>-0.153555</td>\n",
              "      <td>-0.322060</td>\n",
              "      <td>-0.580755</td>\n",
              "      <td>-0.267850</td>\n",
              "      <td>-0.260288</td>\n",
              "      <td>-0.518082</td>\n",
              "      <td>-0.657188</td>\n",
              "      <td>-0.268295</td>\n",
              "      <td>0.036939</td>\n",
              "      <td>0.135541</td>\n",
              "      <td>0.991127</td>\n",
              "      <td>0.331137</td>\n",
              "      <td>-0.196059</td>\n",
              "      <td>1.686764</td>\n",
              "      <td>-0.344468</td>\n",
              "      <td>-0.733223</td>\n",
              "      <td>0.209051</td>\n",
              "      <td>1.088333</td>\n",
              "      <td>0.214718</td>\n",
              "      <td>0.335082</td>\n",
              "      <td>0.824793</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.187845</td>\n",
              "      <td>0.132105</td>\n",
              "      <td>0.179579</td>\n",
              "      <td>0.207629</td>\n",
              "      <td>-0.250042</td>\n",
              "      <td>0.482235</td>\n",
              "      <td>0.046886</td>\n",
              "      <td>0.431239</td>\n",
              "      <td>0.820094</td>\n",
              "      <td>0.590127</td>\n",
              "      <td>0.013195</td>\n",
              "      <td>0.028115</td>\n",
              "      <td>-0.464397</td>\n",
              "      <td>-0.619668</td>\n",
              "      <td>-1.104609</td>\n",
              "      <td>-1.131452</td>\n",
              "      <td>-0.902350</td>\n",
              "      <td>-0.943020</td>\n",
              "      <td>-1.332970</td>\n",
              "      <td>-1.934171</td>\n",
              "      <td>-2.213663</td>\n",
              "      <td>-1.536829</td>\n",
              "      <td>-0.722171</td>\n",
              "      <td>-0.178734</td>\n",
              "      <td>0.308597</td>\n",
              "      <td>0.818689</td>\n",
              "      <td>1.196162</td>\n",
              "      <td>1.374217</td>\n",
              "      <td>1.305235</td>\n",
              "      <td>1.771073</td>\n",
              "      <td>1.881736</td>\n",
              "      <td>-0.052519</td>\n",
              "      <td>1.394695</td>\n",
              "      <td>1.093945</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>1.132673</td>\n",
              "      <td>1.058557</td>\n",
              "      <td>0.523519</td>\n",
              "      <td>-0.176039</td>\n",
              "      <td>0.602042</td>\n",
              "      <td>-0.197005</td>\n",
              "      <td>0.739405</td>\n",
              "      <td>1.331459</td>\n",
              "      <td>1.900056</td>\n",
              "      <td>-0.257707</td>\n",
              "      <td>1.072056</td>\n",
              "      <td>1.057134</td>\n",
              "      <td>0.971437</td>\n",
              "      <td>0.927435</td>\n",
              "      <td>0.487060</td>\n",
              "      <td>-0.315070</td>\n",
              "      <td>-0.449697</td>\n",
              "      <td>-0.595808</td>\n",
              "      <td>-1.260943</td>\n",
              "      <td>-0.277659</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.780564</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.215374</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.778517</td>\n",
              "      <td>-0.592511</td>\n",
              "      <td>-0.056002</td>\n",
              "      <td>1.029934</td>\n",
              "      <td>2.109716</td>\n",
              "      <td>-0.196821</td>\n",
              "      <td>-0.796811</td>\n",
              "      <td>-0.317415</td>\n",
              "      <td>-0.914150</td>\n",
              "      <td>-0.844020</td>\n",
              "      <td>0.008398</td>\n",
              "      <td>1.074835</td>\n",
              "      <td>0.769494</td>\n",
              "      <td>1.025204</td>\n",
              "      <td>1.411707</td>\n",
              "      <td>1.233505</td>\n",
              "      <td>1.445897</td>\n",
              "      <td>1.821751</td>\n",
              "      <td>1.864392</td>\n",
              "      <td>1.640181</td>\n",
              "      <td>1.030471</td>\n",
              "      <td>0.829061</td>\n",
              "      <td>0.724431</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>-0.315311</td>\n",
              "      <td>-1.010462</td>\n",
              "      <td>-1.273895</td>\n",
              "      <td>-1.251656</td>\n",
              "      <td>-0.821466</td>\n",
              "      <td>-0.987414</td>\n",
              "      <td>-1.002292</td>\n",
              "      <td>-0.646149</td>\n",
              "      <td>-0.474538</td>\n",
              "      <td>-0.755014</td>\n",
              "      <td>-0.689435</td>\n",
              "      <td>-0.245891</td>\n",
              "      <td>-0.124805</td>\n",
              "      <td>0.471531</td>\n",
              "      <td>0.230799</td>\n",
              "      <td>-0.253116</td>\n",
              "      <td>-0.735993</td>\n",
              "      <td>-0.655130</td>\n",
              "      <td>-0.175987</td>\n",
              "      <td>-0.810827</td>\n",
              "      <td>-0.895678</td>\n",
              "      <td>-1.030395</td>\n",
              "      <td>-1.088029</td>\n",
              "      <td>-0.728787</td>\n",
              "      <td>-1.237815</td>\n",
              "      <td>-1.125955</td>\n",
              "      <td>-1.080315</td>\n",
              "      <td>0.311217</td>\n",
              "      <td>-0.001053</td>\n",
              "      <td>-0.358354</td>\n",
              "      <td>2.498437</td>\n",
              "      <td>3.354188</td>\n",
              "      <td>0.372213</td>\n",
              "      <td>-0.384879</td>\n",
              "      <td>-0.224460</td>\n",
              "      <td>0.800603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.587172</td>\n",
              "      <td>-0.381402</td>\n",
              "      <td>-0.505530</td>\n",
              "      <td>-0.376901</td>\n",
              "      <td>-0.187537</td>\n",
              "      <td>-1.138334</td>\n",
              "      <td>-0.331595</td>\n",
              "      <td>0.030468</td>\n",
              "      <td>-0.236458</td>\n",
              "      <td>-0.602542</td>\n",
              "      <td>0.383387</td>\n",
              "      <td>1.652909</td>\n",
              "      <td>-0.102535</td>\n",
              "      <td>1.609451</td>\n",
              "      <td>-0.195239</td>\n",
              "      <td>-0.299612</td>\n",
              "      <td>1.813400</td>\n",
              "      <td>2.133541</td>\n",
              "      <td>1.808929</td>\n",
              "      <td>1.398247</td>\n",
              "      <td>0.641789</td>\n",
              "      <td>0.153604</td>\n",
              "      <td>0.040522</td>\n",
              "      <td>-0.356427</td>\n",
              "      <td>-1.359233</td>\n",
              "      <td>-2.762099</td>\n",
              "      <td>-2.986928</td>\n",
              "      <td>-2.846234</td>\n",
              "      <td>-2.270763</td>\n",
              "      <td>-2.048062</td>\n",
              "      <td>-0.887367</td>\n",
              "      <td>0.130098</td>\n",
              "      <td>-0.096410</td>\n",
              "      <td>0.489356</td>\n",
              "      <td>0.508345</td>\n",
              "      <td>-0.245891</td>\n",
              "      <td>-0.499976</td>\n",
              "      <td>-0.145242</td>\n",
              "      <td>0.241974</td>\n",
              "      <td>-0.967230</td>\n",
              "      <td>-1.362519</td>\n",
              "      <td>-0.894370</td>\n",
              "      <td>-0.663159</td>\n",
              "      <td>-1.336588</td>\n",
              "      <td>-0.257707</td>\n",
              "      <td>-0.262237</td>\n",
              "      <td>-1.056856</td>\n",
              "      <td>-1.114775</td>\n",
              "      <td>-1.002462</td>\n",
              "      <td>-0.970857</td>\n",
              "      <td>-0.179026</td>\n",
              "      <td>-0.661062</td>\n",
              "      <td>-0.274319</td>\n",
              "      <td>1.696771</td>\n",
              "      <td>1.473417</td>\n",
              "      <td>-0.096963</td>\n",
              "      <td>-0.326440</td>\n",
              "      <td>0.304657</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.965261</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c732ca66-9558-4255-90fb-4d020d8463d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c732ca66-9558-4255-90fb-4d020d8463d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c732ca66-9558-4255-90fb-4d020d8463d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  attribute_1 attribute_2  ... location_loc_D location_loc_E\n",
              "0    0.926945    0.502972  ...            0.0            1.0\n",
              "1   -0.137929   -0.638156  ...            0.0            1.0\n",
              "2   -0.187845    0.132105  ...            0.0            1.0\n",
              "3   -0.778517   -0.592511  ...            1.0            0.0\n",
              "4   -0.587172   -0.381402  ...            1.0            0.0\n",
              "\n",
              "[5 rows x 68 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV_hXT28GpJH"
      },
      "source": [
        "And that's it! Now the training data is fully prepared and ready for the phase of model building. Below you find once more the full code needed to set up the pipeline, without all the detours taken above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_3Gol5IGxI"
      },
      "source": [
        "#from sklearn.pipeline import Pipeline\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.impute import SimpleImputer\n",
        "\n",
        "#num_pipeline = Pipeline([\n",
        "#        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "#        ('std_scaler', StandardScaler()),\n",
        "#    ])\n",
        "#\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "#\n",
        "#cat_pipeline = Pipeline([\n",
        "#        ('cat_imputer', SimpleImputer(strategy = 'most_frequent')),\n",
        "#        ('cat_encoder', OneHotEncoder(sparse=False))])\n",
        "#\n",
        "#from sklearn.compose import ColumnTransformer\n",
        "#\n",
        "#full_pipeline = ColumnTransformer([\n",
        "#        (\"num\", num_pipeline, num_features),\n",
        "#        (\"cat\", cat_pipeline, cat_features)])\n",
        "#\n",
        "#num_features = X_train.select_dtypes(include=['float']).columns\n",
        "#cat_features = X_train.select_dtypes(exclude=['float']).columns\n",
        "#X_train_prep = full_pipeline.fit_transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy4ACaEvxM9y"
      },
      "source": [
        "## Building models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtJ7pFv27tB0"
      },
      "source": [
        "We now build a gradient boosting model, as it will demonstrate how to tune hyperparameters. \n",
        "\n",
        "We start off training a gradient boosting classifier wiht default hyperparameter settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThciEzL675hy",
        "outputId": "c35d9c99-8b59-483c-f40d-3c07766e6a87"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB_clf = GradientBoostingClassifier(random_state=42)\n",
        "GB_clf.fit(X_train_prep, y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zrXqzJpAvA5"
      },
      "source": [
        "We can check the accuracy of this classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR1O6bQMA4aB",
        "outputId": "30e34278-6d67-4a13-b197-8c9f9baa78e3"
      },
      "source": [
        "accuracy_score(GB_clf.predict(X_train_prep), y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmCv0KVUBDwg"
      },
      "source": [
        "and see that the model gets a perfect accuracy on the training set, which is simply the result of using a highly flexible model, while not using cross-validation (meaning there is no guarding against overfitting and the model simply remembers all the training instances). An honest evaluation of model assessment can only be obtained by assessing the accuracy on the test set, for which we first need to prepare the test features, which is really simple now that we have set up the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "kJ88A73RBsCR",
        "outputId": "0de049aa-87a4-4386-c8ba-276ad3e9eb77"
      },
      "source": [
        "X_test_prep = full_pipeline.transform(X_test)\n",
        "pd.DataFrame(X_test_prep, columns=[num_features.tolist() + cat_names.tolist()]).head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0bd06e9a-d562-4dfb-962e-65747e13c0cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>attribute_11</th>\n",
              "      <th>attribute_12</th>\n",
              "      <th>attribute_13</th>\n",
              "      <th>attribute_14</th>\n",
              "      <th>attribute_15</th>\n",
              "      <th>attribute_16</th>\n",
              "      <th>attribute_17</th>\n",
              "      <th>attribute_18</th>\n",
              "      <th>attribute_19</th>\n",
              "      <th>attribute_20</th>\n",
              "      <th>attribute_21</th>\n",
              "      <th>attribute_22</th>\n",
              "      <th>attribute_23</th>\n",
              "      <th>attribute_24</th>\n",
              "      <th>attribute_25</th>\n",
              "      <th>attribute_26</th>\n",
              "      <th>attribute_27</th>\n",
              "      <th>attribute_28</th>\n",
              "      <th>attribute_29</th>\n",
              "      <th>attribute_30</th>\n",
              "      <th>attribute_31</th>\n",
              "      <th>attribute_32</th>\n",
              "      <th>attribute_33</th>\n",
              "      <th>attribute_34</th>\n",
              "      <th>attribute_35</th>\n",
              "      <th>attribute_36</th>\n",
              "      <th>attribute_37</th>\n",
              "      <th>attribute_38</th>\n",
              "      <th>attribute_39</th>\n",
              "      <th>attribute_40</th>\n",
              "      <th>attribute_41</th>\n",
              "      <th>attribute_42</th>\n",
              "      <th>attribute_43</th>\n",
              "      <th>attribute_44</th>\n",
              "      <th>attribute_45</th>\n",
              "      <th>attribute_46</th>\n",
              "      <th>attribute_47</th>\n",
              "      <th>attribute_48</th>\n",
              "      <th>attribute_49</th>\n",
              "      <th>attribute_50</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "      <th>batch_first</th>\n",
              "      <th>batch_second</th>\n",
              "      <th>batch_third</th>\n",
              "      <th>location_loc_A</th>\n",
              "      <th>location_loc_B</th>\n",
              "      <th>location_loc_C</th>\n",
              "      <th>location_loc_D</th>\n",
              "      <th>location_loc_E</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.312634</td>\n",
              "      <td>-0.504073</td>\n",
              "      <td>-0.457452</td>\n",
              "      <td>0.039206</td>\n",
              "      <td>-0.519081</td>\n",
              "      <td>-0.498855</td>\n",
              "      <td>0.155699</td>\n",
              "      <td>-0.684103</td>\n",
              "      <td>-0.674914</td>\n",
              "      <td>-0.431003</td>\n",
              "      <td>-0.010791</td>\n",
              "      <td>-0.009618</td>\n",
              "      <td>0.047351</td>\n",
              "      <td>-0.095280</td>\n",
              "      <td>-0.118131</td>\n",
              "      <td>-0.817829</td>\n",
              "      <td>-0.926473</td>\n",
              "      <td>-0.926879</td>\n",
              "      <td>-1.027920</td>\n",
              "      <td>-0.966034</td>\n",
              "      <td>-0.807373</td>\n",
              "      <td>-0.968841</td>\n",
              "      <td>-0.691999</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>0.303357</td>\n",
              "      <td>0.188777</td>\n",
              "      <td>0.704892</td>\n",
              "      <td>1.354697</td>\n",
              "      <td>1.259931</td>\n",
              "      <td>0.588292</td>\n",
              "      <td>0.550684</td>\n",
              "      <td>-0.052519</td>\n",
              "      <td>-0.105583</td>\n",
              "      <td>-0.199153</td>\n",
              "      <td>-0.666384</td>\n",
              "      <td>-0.972613</td>\n",
              "      <td>-0.809215</td>\n",
              "      <td>-0.865519</td>\n",
              "      <td>-0.460480</td>\n",
              "      <td>-0.390605</td>\n",
              "      <td>-0.304552</td>\n",
              "      <td>-0.076243</td>\n",
              "      <td>-0.940252</td>\n",
              "      <td>-0.732621</td>\n",
              "      <td>-0.289865</td>\n",
              "      <td>0.215736</td>\n",
              "      <td>-0.268295</td>\n",
              "      <td>0.868298</td>\n",
              "      <td>-0.105350</td>\n",
              "      <td>-0.179860</td>\n",
              "      <td>0.263115</td>\n",
              "      <td>0.173829</td>\n",
              "      <td>-0.627957</td>\n",
              "      <td>-0.386126</td>\n",
              "      <td>-0.049876</td>\n",
              "      <td>-0.249970</td>\n",
              "      <td>-0.343906</td>\n",
              "      <td>-0.354899</td>\n",
              "      <td>-0.550859</td>\n",
              "      <td>-0.844312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.383349</td>\n",
              "      <td>-0.738005</td>\n",
              "      <td>-1.099291</td>\n",
              "      <td>-0.250087</td>\n",
              "      <td>-0.067964</td>\n",
              "      <td>1.134211</td>\n",
              "      <td>0.396981</td>\n",
              "      <td>-0.183433</td>\n",
              "      <td>-0.140253</td>\n",
              "      <td>-0.594443</td>\n",
              "      <td>-1.362831</td>\n",
              "      <td>-1.657806</td>\n",
              "      <td>-1.272754</td>\n",
              "      <td>-0.308527</td>\n",
              "      <td>0.442707</td>\n",
              "      <td>1.080059</td>\n",
              "      <td>1.223888</td>\n",
              "      <td>1.397371</td>\n",
              "      <td>1.541766</td>\n",
              "      <td>1.627722</td>\n",
              "      <td>1.239169</td>\n",
              "      <td>0.153604</td>\n",
              "      <td>0.546330</td>\n",
              "      <td>-0.717911</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>-1.706751</td>\n",
              "      <td>-2.062757</td>\n",
              "      <td>0.149119</td>\n",
              "      <td>-0.232082</td>\n",
              "      <td>0.192363</td>\n",
              "      <td>-0.219116</td>\n",
              "      <td>-0.360655</td>\n",
              "      <td>0.155844</td>\n",
              "      <td>-0.045750</td>\n",
              "      <td>-0.262986</td>\n",
              "      <td>-0.623427</td>\n",
              "      <td>-1.013390</td>\n",
              "      <td>-0.978948</td>\n",
              "      <td>-0.903770</td>\n",
              "      <td>-1.271839</td>\n",
              "      <td>-0.800396</td>\n",
              "      <td>-0.580135</td>\n",
              "      <td>-0.843119</td>\n",
              "      <td>-0.253319</td>\n",
              "      <td>0.091189</td>\n",
              "      <td>-0.668258</td>\n",
              "      <td>-0.522297</td>\n",
              "      <td>-0.292792</td>\n",
              "      <td>-0.277020</td>\n",
              "      <td>-0.528829</td>\n",
              "      <td>0.135574</td>\n",
              "      <td>-0.174923</td>\n",
              "      <td>-1.222711</td>\n",
              "      <td>-0.872136</td>\n",
              "      <td>-0.647805</td>\n",
              "      <td>-0.827995</td>\n",
              "      <td>-0.902828</td>\n",
              "      <td>-0.609728</td>\n",
              "      <td>-0.504230</td>\n",
              "      <td>-1.062021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.845071</td>\n",
              "      <td>-0.318640</td>\n",
              "      <td>-0.678610</td>\n",
              "      <td>-0.406622</td>\n",
              "      <td>-0.602420</td>\n",
              "      <td>-1.702826</td>\n",
              "      <td>-1.501731</td>\n",
              "      <td>-0.835714</td>\n",
              "      <td>0.055562</td>\n",
              "      <td>0.379570</td>\n",
              "      <td>0.708804</td>\n",
              "      <td>0.542042</td>\n",
              "      <td>-0.319653</td>\n",
              "      <td>-1.147798</td>\n",
              "      <td>-1.100496</td>\n",
              "      <td>0.325839</td>\n",
              "      <td>-0.422146</td>\n",
              "      <td>0.972597</td>\n",
              "      <td>1.135553</td>\n",
              "      <td>1.546542</td>\n",
              "      <td>1.520266</td>\n",
              "      <td>0.776521</td>\n",
              "      <td>-0.317776</td>\n",
              "      <td>-0.169152</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>-0.109696</td>\n",
              "      <td>-1.395054</td>\n",
              "      <td>-2.411687</td>\n",
              "      <td>-1.828941</td>\n",
              "      <td>-0.945368</td>\n",
              "      <td>-0.067039</td>\n",
              "      <td>-0.052519</td>\n",
              "      <td>-0.968855</td>\n",
              "      <td>-0.127866</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>-0.245891</td>\n",
              "      <td>0.867569</td>\n",
              "      <td>-0.049772</td>\n",
              "      <td>-0.265176</td>\n",
              "      <td>-0.512093</td>\n",
              "      <td>-0.550286</td>\n",
              "      <td>-0.528072</td>\n",
              "      <td>-1.203039</td>\n",
              "      <td>-0.925426</td>\n",
              "      <td>-0.337583</td>\n",
              "      <td>-0.262237</td>\n",
              "      <td>0.036508</td>\n",
              "      <td>-0.145897</td>\n",
              "      <td>0.110621</td>\n",
              "      <td>-0.179860</td>\n",
              "      <td>-0.153518</td>\n",
              "      <td>-0.481402</td>\n",
              "      <td>0.079319</td>\n",
              "      <td>-1.024881</td>\n",
              "      <td>-0.092586</td>\n",
              "      <td>-0.555983</td>\n",
              "      <td>0.721540</td>\n",
              "      <td>-0.894536</td>\n",
              "      <td>0.117482</td>\n",
              "      <td>-0.021854</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.071374</td>\n",
              "      <td>0.189162</td>\n",
              "      <td>-0.469472</td>\n",
              "      <td>-0.796970</td>\n",
              "      <td>-0.660395</td>\n",
              "      <td>-0.059344</td>\n",
              "      <td>-0.102929</td>\n",
              "      <td>0.553468</td>\n",
              "      <td>0.233499</td>\n",
              "      <td>0.652706</td>\n",
              "      <td>0.398579</td>\n",
              "      <td>1.272558</td>\n",
              "      <td>2.773776</td>\n",
              "      <td>3.173264</td>\n",
              "      <td>3.383121</td>\n",
              "      <td>2.814629</td>\n",
              "      <td>2.005255</td>\n",
              "      <td>-0.318653</td>\n",
              "      <td>0.849642</td>\n",
              "      <td>-0.051347</td>\n",
              "      <td>0.160892</td>\n",
              "      <td>-0.898389</td>\n",
              "      <td>-0.275451</td>\n",
              "      <td>-1.703063</td>\n",
              "      <td>0.197917</td>\n",
              "      <td>-0.596609</td>\n",
              "      <td>-0.816674</td>\n",
              "      <td>-1.510525</td>\n",
              "      <td>-1.247755</td>\n",
              "      <td>-0.369745</td>\n",
              "      <td>0.259904</td>\n",
              "      <td>0.211808</td>\n",
              "      <td>-0.117814</td>\n",
              "      <td>-0.797426</td>\n",
              "      <td>-1.010380</td>\n",
              "      <td>-0.342670</td>\n",
              "      <td>0.132966</td>\n",
              "      <td>0.331162</td>\n",
              "      <td>0.443131</td>\n",
              "      <td>-0.153555</td>\n",
              "      <td>-0.135728</td>\n",
              "      <td>-0.127066</td>\n",
              "      <td>-1.287371</td>\n",
              "      <td>-0.669901</td>\n",
              "      <td>-0.467598</td>\n",
              "      <td>-0.412073</td>\n",
              "      <td>-0.642370</td>\n",
              "      <td>-0.691282</td>\n",
              "      <td>-0.789259</td>\n",
              "      <td>-0.939838</td>\n",
              "      <td>-0.459616</td>\n",
              "      <td>-0.935836</td>\n",
              "      <td>-1.367381</td>\n",
              "      <td>-0.997109</td>\n",
              "      <td>-0.277659</td>\n",
              "      <td>0.158048</td>\n",
              "      <td>-0.326440</td>\n",
              "      <td>-0.324919</td>\n",
              "      <td>-0.504230</td>\n",
              "      <td>-0.263754</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.312634</td>\n",
              "      <td>0.037962</td>\n",
              "      <td>0.718051</td>\n",
              "      <td>0.461256</td>\n",
              "      <td>-0.412190</td>\n",
              "      <td>-0.180157</td>\n",
              "      <td>-1.768245</td>\n",
              "      <td>-0.808683</td>\n",
              "      <td>-0.456963</td>\n",
              "      <td>-0.207562</td>\n",
              "      <td>-1.237302</td>\n",
              "      <td>-1.335564</td>\n",
              "      <td>-2.043936</td>\n",
              "      <td>-1.195810</td>\n",
              "      <td>-1.220272</td>\n",
              "      <td>-0.746939</td>\n",
              "      <td>-0.992058</td>\n",
              "      <td>-0.744215</td>\n",
              "      <td>-0.497891</td>\n",
              "      <td>-0.614386</td>\n",
              "      <td>-1.062989</td>\n",
              "      <td>-1.929287</td>\n",
              "      <td>0.211499</td>\n",
              "      <td>-1.722662</td>\n",
              "      <td>-2.324566</td>\n",
              "      <td>-2.002552</td>\n",
              "      <td>-1.223928</td>\n",
              "      <td>0.241606</td>\n",
              "      <td>1.179247</td>\n",
              "      <td>1.004242</td>\n",
              "      <td>-0.143325</td>\n",
              "      <td>-0.917860</td>\n",
              "      <td>0.633854</td>\n",
              "      <td>1.043863</td>\n",
              "      <td>-0.140637</td>\n",
              "      <td>0.328331</td>\n",
              "      <td>1.218494</td>\n",
              "      <td>1.425756</td>\n",
              "      <td>-0.176039</td>\n",
              "      <td>-0.153555</td>\n",
              "      <td>-0.395217</td>\n",
              "      <td>-1.354256</td>\n",
              "      <td>-1.831769</td>\n",
              "      <td>-1.628505</td>\n",
              "      <td>-1.291947</td>\n",
              "      <td>-1.273137</td>\n",
              "      <td>-1.361658</td>\n",
              "      <td>-1.463258</td>\n",
              "      <td>-1.520239</td>\n",
              "      <td>-1.567983</td>\n",
              "      <td>-1.343899</td>\n",
              "      <td>-0.819586</td>\n",
              "      <td>2.217221</td>\n",
              "      <td>1.307964</td>\n",
              "      <td>-0.633568</td>\n",
              "      <td>0.974084</td>\n",
              "      <td>1.542457</td>\n",
              "      <td>0.019849</td>\n",
              "      <td>0.863537</td>\n",
              "      <td>1.260212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bd06e9a-d562-4dfb-962e-65747e13c0cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bd06e9a-d562-4dfb-962e-65747e13c0cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bd06e9a-d562-4dfb-962e-65747e13c0cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  attribute_1 attribute_2  ... location_loc_D location_loc_E\n",
              "0   -0.312634   -0.504073  ...            0.0            1.0\n",
              "1   -0.383349   -0.738005  ...            0.0            1.0\n",
              "2   -0.845071   -0.318640  ...            0.0            1.0\n",
              "3   -0.071374    0.189162  ...            0.0            1.0\n",
              "4   -0.312634    0.037962  ...            1.0            0.0\n",
              "\n",
              "[5 rows x 68 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWJH1WBlB852"
      },
      "source": [
        "Be careful not to use 'fit_transform' with the pipeline, but only 'transform', as we have to use the fitted information (scaling etc) from the training data. One way to remember this is to see the test data as something that does not come in batches, but in single instances: you want your model to work on new, single observations. A single observation cannot be scaled to mean 0 and standard deviation 1, which is why we apply the preprocessing parameters derived in the train set to prepare the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgmh9mfzCyTR",
        "outputId": "5182de55-fb11-432f-f02e-2a73678dc544"
      },
      "source": [
        "accuracy_score(GB_clf.predict(X_test_prep), y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8253968253968254"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcvowRyjC26k"
      },
      "source": [
        "The accuracy of the default gradient boosting classifier is 0.825 on the test set. Please realize that this model is based on the default values for the range of hyperparameters available in this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg-4ccdADonv",
        "outputId": "cdb0bb1c-d7cf-408c-e4bb-ea83fa6aa89b"
      },
      "source": [
        "GB_clf.get_params"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of GradientBoostingClassifier(random_state=42)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVQd8tCKDwNz"
      },
      "source": [
        "The natural thing to do is to 'tune the hyperparameters', which means nothing more than trying out a lot of different values for these hyperparameters, and see which specific setting generates the best performance. This requires us to do two things: \n",
        "- defining the different hyperparameters to be tried out (a.k.a. defining a grid of hyperparameter values)\n",
        "- defining the cross-validation strategy: remember that comparing the performance for all the possible different hyperparameter settings should be done within the train set (to prevent information leakage from the test into the train set)\n",
        "After doing these two things, we can simply fit the model again and assess its accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrCCdpaUFZPB",
        "outputId": "1ef2ee12-4975-4b9e-8e61-a423933e5d3e"
      },
      "source": [
        "# defining the grid (as a dictionary where the keys have the same names as \n",
        "# corresponding hyperparameter in the gradientBoostingClassifier object)\n",
        "max_feat = np.linspace(1, len(X_train.columns), 4).astype(int)\n",
        "max_depth = np.linspace(1, 3, 3).astype(int)\n",
        "learning_rate = np.array([0.05, 0.1, 0.15])\n",
        "n_estimators = np.linspace(50, 300, 6).astype(int)\n",
        "grid = dict()\n",
        "grid['max_features'] = max_feat\n",
        "grid['max_depth'] = max_depth\n",
        "grid['n_estimators'] = n_estimators\n",
        "grid['learning_rate'] = learning_rate\n",
        "grid"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': array([0.05, 0.1 , 0.15]),\n",
              " 'max_depth': array([1, 2, 3]),\n",
              " 'max_features': array([ 1, 21, 41, 62]),\n",
              " 'n_estimators': array([ 50, 100, 150, 200, 250, 300])}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk4wy19v8ZG1"
      },
      "source": [
        "# defining the cross validation strategy\n",
        "GB_clf_tune = GradientBoostingClassifier(random_state=42)\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "gscv_gb_1 = GridSearchCV(GB_clf_tune, param_grid = grid, scoring='accuracy', cv = cv, n_jobs=-1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmTQgMsk7-2m",
        "outputId": "656ea511-6387-40ec-e64e-0dc95b0d9a5c"
      },
      "source": [
        "# and now we simply train the model again, this time trying out the different\n",
        "# hyperparameter values defined in 'grid', using the cross-validation strategy outline in 'cv'\n",
        "# this naturally takes longer, as many more models are being trained (and compared)\n",
        "gscv_gb_1.fit(X_train_prep, y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
              "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
              "             param_grid={'learning_rate': array([0.05, 0.1 , 0.15]),\n",
              "                         'max_depth': array([1, 2, 3]),\n",
              "                         'max_features': array([ 1, 21, 41, 62]),\n",
              "                         'n_estimators': array([ 50, 100, 150, 200, 250, 300])},\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wc1oUJsG0_u",
        "outputId": "8b74cb8e-e0f9-4fdb-a971-36d6d9a8d219"
      },
      "source": [
        "# having tried out all the different hyperparameter settings, we are obviously\n",
        "# wondering what the best setting turned out to be\n",
        "gscv_gb_1.best_estimator_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=0.15, max_features=41,\n",
              "                           n_estimators=150, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC3eioxcIjt1"
      },
      "source": [
        "The best performance occurred at the hyperparameter values shown above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ2pR0faMtsw",
        "outputId": "09eded46-32e0-4c1e-ca93-6af59fcef238"
      },
      "source": [
        "#best_score_ provides the mean cross-validated score of the best_estimator \n",
        "# (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "gscv_gb_1.best_score_"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.930952380952381"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijNmilbQNZgV"
      },
      "source": [
        "As some of the optimal hyperparameters are on the edge of our grid (learning rate and max_depth), we could try to further optimize performance by redefing our grid to be centered around the currently optimal parameter values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hikngGR4OMas",
        "outputId": "072f358a-54cf-419d-a096-7a3b10fa43d1"
      },
      "source": [
        "max_feat = np.linspace(1, len(X_train.columns), 4).astype(int)\n",
        "max_depth = np.linspace(1, 4, 4).astype(int)\n",
        "learning_rate = np.array([0.025, 0.05, 0.075])\n",
        "n_estimators = np.linspace(150, 400, 6).astype(int)\n",
        "grid2 = dict()\n",
        "grid2['max_features'] = max_feat\n",
        "grid2['max_depth'] = max_depth\n",
        "grid2['n_estimators'] = n_estimators\n",
        "grid2['learning_rate'] = learning_rate\n",
        "grid2"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': array([0.025, 0.05 , 0.075]),\n",
              " 'max_depth': array([1, 2, 3, 4]),\n",
              " 'max_features': array([ 1, 21, 41, 62]),\n",
              " 'n_estimators': array([150, 200, 250, 300, 350, 400])}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYPJXbIiOzjf"
      },
      "source": [
        "GB_clf_tune_2 = GradientBoostingClassifier(random_state=42)\n",
        "gscv_gb_2 = GridSearchCV(GB_clf_tune_2, param_grid = grid2, scoring='accuracy', cv = cv, n_jobs=-1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DilJ949O-uw",
        "outputId": "a8fd7997-b1d3-4ab9-b025-475c5bdc0cbd"
      },
      "source": [
        "gscv_gb_2.fit(X_train_prep, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
              "             estimator=GradientBoostingClassifier(random_state=42), n_jobs=-1,\n",
              "             param_grid={'learning_rate': array([0.025, 0.05 , 0.075]),\n",
              "                         'max_depth': array([1, 2, 3, 4]),\n",
              "                         'max_features': array([ 1, 21, 41, 62]),\n",
              "                         'n_estimators': array([150, 200, 250, 300, 350, 400])},\n",
              "             scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MesOC4hcUyIH",
        "outputId": "d53b33d8-f99a-416e-d960-4c42929e5368"
      },
      "source": [
        "gscv_gb_2.best_estimator_"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=0.075, max_features=41,\n",
              "                           n_estimators=350, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K1vqSJVfvwz"
      },
      "source": [
        "We see that the model actually chooses the same hyperparameter values. As they are currently in the center of our grid (grid2), we can stop searching for better parameter settings. To complete the process, we again view the mean cross-validated scores for the best estimator, but it will result in the same performance estimate (because we not only use the same hyperparameter settings, but due to setting the same random_state within the cross-validation strategy, our folds contain identical instances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBbAZwgxU2Gs",
        "outputId": "b1114752-a14a-422b-d2f2-1eeae631912f"
      },
      "source": [
        "gscv_gb_2.best_score_"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9328571428571428"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcaUWvcExO6Q"
      },
      "source": [
        "## Assess results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQXgZe5gd4L"
      },
      "source": [
        "We assess the accuracy on the test set simply by using the predict option on the prepared test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfazg3u8VyYS",
        "outputId": "765f406b-4509-4d1d-c88e-89f7e6bcb8fc"
      },
      "source": [
        "accuracy_score(gscv_gb_2.predict(X_test_prep), y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8571428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlmS3XKPgyQy"
      },
      "source": [
        "Accuracy is higher than the performance we got for our non-tuned gradient boosting classifier (accuracy: 0.825), but notice that it is lower than the cross-validated performance on the train set. This indicates that the model is somewhat overfitting the train set, which is not too surprising given that we train a very flexible model on a very small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ATXPnShNKr"
      },
      "source": [
        "To gain more insight in the type of right and wrong predictions, we can plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, gscv_gb_2.best_estimator_.predict(X_test_prep), labels=gscv_gb_2.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gscv_gb_2.classes_)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "mvEmlD04M7JN",
        "outputId": "8f24b2e4-cb9c-4f7a-84bb-98fc137d06b6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff3ca2b2c90>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG219z6ohceY"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This notebook took a 'small step by small step' approach to developing a model. Sklearn has amazing abilities, but the risk in using such a powerful library is that you lose sight of what is happening and start leaning on the preprogrammed features too easily. \n",
        "\n",
        "Especially when you start working with sklearn and its wide array of applications, it really pays off to take this step by step approach to really keep track of what is happening as much as possible. "
      ]
    }
  ]
}